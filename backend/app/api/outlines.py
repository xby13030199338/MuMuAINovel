"""å¤§çº²ç®¡ç†API"""
from fastapi import APIRouter, Depends, HTTPException, Request
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, delete
from typing import List, AsyncGenerator, Dict, Any
import json

from app.database import get_db
from app.api.common import verify_project_access
from app.models.outline import Outline
from app.models.project import Project
from app.models.chapter import Chapter
from app.models.character import Character
from app.models.relationship import CharacterRelationship, Organization, OrganizationMember
from app.models.generation_history import GenerationHistory
from app.schemas.outline import (
    OutlineCreate,
    OutlineUpdate,
    OutlineResponse,
    OutlineListResponse,
    OutlineGenerateRequest,
    OutlineExpansionRequest,
    OutlineExpansionResponse,
    BatchOutlineExpansionRequest,
    BatchOutlineExpansionResponse,
    CreateChaptersFromPlansRequest,
    CreateChaptersFromPlansResponse
)
from app.services.ai_service import AIService
from app.services.prompt_service import prompt_service, PromptService
from app.services.memory_service import memory_service
from app.services.plot_expansion_service import PlotExpansionService
from app.services.foreshadow_service import foreshadow_service
from app.services.memory_service import memory_service
from app.logger import get_logger
from app.api.settings import get_user_ai_service
from app.utils.sse_response import SSEResponse, create_sse_response, WizardProgressTracker

router = APIRouter(prefix="/outlines", tags=["å¤§çº²ç®¡ç†"])
logger = get_logger(__name__)


def _build_chapters_brief(outlines: List[Outline], max_recent: int = 20) -> str:
    """æ„å»ºç« èŠ‚æ¦‚è§ˆå­—ç¬¦ä¸²"""
    target = outlines[-max_recent:] if len(outlines) > max_recent else outlines
    return "\n".join([f"ç¬¬{o.order_index}ç« ã€Š{o.title}ã€‹" for o in target])


def _build_characters_info(characters: List[Character]) -> str:
    """æ„å»ºè§’è‰²ä¿¡æ¯å­—ç¬¦ä¸²"""
    return "\n".join([
        f"- {char.name} ({'ç»„ç»‡' if char.is_organization else 'è§’è‰²'}, {char.role_type}): "
        f"{char.personality[:100] if char.personality else 'æš‚æ— æè¿°'}"
        for char in characters
    ])


@router.post("", response_model=OutlineResponse, summary="åˆ›å»ºå¤§çº²")
async def create_outline(
    outline: OutlineCreate,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """åˆ›å»ºæ–°çš„ç« èŠ‚å¤§çº²ï¼ˆone-to-oneæ¨¡å¼ä¼šè‡ªåŠ¨åˆ›å»ºå¯¹åº”ç« èŠ‚ï¼‰"""
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    project = await verify_project_access(outline.project_id, user_id, db)
    
    # åˆ›å»ºå¤§çº²
    db_outline = Outline(**outline.model_dump())
    db.add(db_outline)
    await db.flush()  # ç¡®ä¿å¤§çº²æœ‰ID
    
    # å¦‚æœæ˜¯one-to-oneæ¨¡å¼ï¼Œè‡ªåŠ¨åˆ›å»ºå¯¹åº”çš„ç« èŠ‚
    if project.outline_mode == 'one-to-one':
        chapter = Chapter(
            project_id=outline.project_id,
            title=db_outline.title,
            summary=db_outline.content,
            chapter_number=db_outline.order_index,
            sub_index=1,
            outline_id=None,  # one-to-oneæ¨¡å¼ä¸å…³è”outline_id
            status='pending',
            content=""
        )
        db.add(chapter)
        logger.info(f"ä¸€å¯¹ä¸€æ¨¡å¼ï¼šä¸ºæ‰‹åŠ¨åˆ›å»ºçš„å¤§çº² {db_outline.title} (åºå·{db_outline.order_index}) è‡ªåŠ¨åˆ›å»ºäº†å¯¹åº”ç« èŠ‚")
    
    await db.commit()
    await db.refresh(db_outline)
    return db_outline


@router.get("", response_model=OutlineListResponse, summary="è·å–å¤§çº²åˆ—è¡¨")
async def get_outlines(
    project_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """è·å–æŒ‡å®šé¡¹ç›®çš„æ‰€æœ‰å¤§çº²ï¼ˆä¼˜åŒ–ç‰ˆï¼šåç«¯å®Œå…¨è§£æstructureï¼Œæ„å»ºæ ‡å‡†JSONè¿”å›ï¼‰"""
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(project_id, user_id, db)
    
    # è·å–æ€»æ•°
    count_result = await db.execute(
        select(func.count(Outline.id)).where(Outline.project_id == project_id)
    )
    total = count_result.scalar_one()
    
    # è·å–å¤§çº²åˆ—è¡¨
    result = await db.execute(
        select(Outline)
        .where(Outline.project_id == project_id)
        .order_by(Outline.order_index)
    )
    outlines = result.scalars().all()
    
    # ğŸ”§ ä¼˜åŒ–ï¼šåç«¯å®Œå…¨è§£æstructureï¼Œæå–æ‰€æœ‰å­—æ®µå¡«å……åˆ°outlineå¯¹è±¡
    for outline in outlines:
        if outline.structure:
            try:
                structure_data = json.loads(outline.structure)
                
                # ä»structureä¸­æå–æ‰€æœ‰å­—æ®µå¡«å……åˆ°outlineå¯¹è±¡
                outline.title = structure_data.get("title", f"ç¬¬{outline.order_index}ç« ")
                outline.content = structure_data.get("summary") or structure_data.get("content", "")
                
                # structureå­—æ®µä¿æŒä¸å˜ï¼Œä¾›å‰ç«¯ä½¿ç”¨å…¶ä»–å­—æ®µï¼ˆå¦‚charactersã€scenesç­‰ï¼‰
                
            except json.JSONDecodeError:
                logger.warning(f"è§£æå¤§çº² {outline.id} çš„structureå¤±è´¥")
                outline.title = f"ç¬¬{outline.order_index}ç« "
                outline.content = "è§£æå¤±è´¥"
        else:
            # æ²¡æœ‰structureçš„å¼‚å¸¸æƒ…å†µ
            outline.title = f"ç¬¬{outline.order_index}ç« "
            outline.content = "æš‚æ— å†…å®¹"
    
    return OutlineListResponse(total=total, items=outlines)


@router.get("/project/{project_id}", response_model=OutlineListResponse, summary="è·å–é¡¹ç›®çš„æ‰€æœ‰å¤§çº²")
async def get_project_outlines(
    project_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """è·å–æŒ‡å®šé¡¹ç›®çš„æ‰€æœ‰å¤§çº²ï¼ˆè·¯å¾„å‚æ•°ç‰ˆæœ¬ï¼Œå…¼å®¹æ—§APIï¼‰"""
    return await get_outlines(project_id, request, db)


@router.get("/{outline_id}", response_model=OutlineResponse, summary="è·å–å¤§çº²è¯¦æƒ…")
async def get_outline(
    outline_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """æ ¹æ®IDè·å–å¤§çº²è¯¦æƒ…"""
    result = await db.execute(
        select(Outline).where(Outline.id == outline_id)
    )
    outline = result.scalar_one_or_none()
    
    if not outline:
        raise HTTPException(status_code=404, detail="å¤§çº²ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(outline.project_id, user_id, db)
    
    return outline


@router.put("/{outline_id}", response_model=OutlineResponse, summary="æ›´æ–°å¤§çº²")
async def update_outline(
    outline_id: str,
    outline_update: OutlineUpdate,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """æ›´æ–°å¤§çº²ä¿¡æ¯å¹¶åŒæ­¥æ›´æ–°structureå­—æ®µå’Œå…³è”ç« èŠ‚"""
    result = await db.execute(
        select(Outline).where(Outline.id == outline_id)
    )
    outline = result.scalar_one_or_none()
    
    if not outline:
        raise HTTPException(status_code=404, detail="å¤§çº²ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    project = await verify_project_access(outline.project_id, user_id, db)
    
    # æ›´æ–°å­—æ®µ
    update_data = outline_update.model_dump(exclude_unset=True)
    
    # ğŸ”§ ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœç›´æ¥ä¼ é€’äº†structureå­—æ®µï¼Œä¼˜å…ˆä½¿ç”¨å®ƒ
    if 'structure' in update_data:
        # ç›´æ¥ä½¿ç”¨å‰ç«¯ä¼ é€’çš„structureï¼ˆå‰ç«¯å·²ç»å¤„ç†å¥½äº†å®Œæ•´çš„JSONï¼‰
        outline.structure = update_data['structure']
        logger.info(f"ç›´æ¥æ›´æ–°å¤§çº² {outline_id} çš„structureå­—æ®µ")
        # ä»update_dataä¸­ç§»é™¤structureï¼Œé¿å…åç»­é‡å¤å¤„ç†
        structure_updated = True
        del update_data['structure']
    else:
        structure_updated = False
    
    # æ›´æ–°å…¶ä»–å­—æ®µ
    for field, value in update_data.items():
        setattr(outline, field, value)
    
    # å¦‚æœæ²¡æœ‰ç›´æ¥æ›´æ–°structureï¼Œä½†ä¿®æ”¹äº†contentæˆ–titleï¼Œåˆ™åŒæ­¥æ›´æ–°structureå­—æ®µ
    if not structure_updated and ('content' in update_data or 'title' in update_data):
        try:
            # å°è¯•è§£æç°æœ‰çš„structure
            if outline.structure:
                structure_data = json.loads(outline.structure)
            else:
                structure_data = {}
            
            # æ›´æ–°structureä¸­çš„å¯¹åº”å­—æ®µ
            if 'title' in update_data:
                structure_data['title'] = outline.title
            if 'content' in update_data:
                structure_data['summary'] = outline.content
                structure_data['content'] = outline.content
            
            # ä¿å­˜æ›´æ–°åçš„structure
            outline.structure = json.dumps(structure_data, ensure_ascii=False)
            logger.info(f"åŒæ­¥æ›´æ–°å¤§çº² {outline_id} çš„structureå­—æ®µ")
        except json.JSONDecodeError:
            logger.warning(f"å¤§çº² {outline_id} çš„structureå­—æ®µæ ¼å¼é”™è¯¯ï¼Œè·³è¿‡æ›´æ–°")
    
    # ğŸ”§ ä¼ ç»Ÿæ¨¡å¼ï¼ˆone-to-oneï¼‰ï¼šåŒæ­¥æ›´æ–°å…³è”ç« èŠ‚çš„æ ‡é¢˜
    if 'title' in update_data and project.outline_mode == 'one-to-one':
        try:
            # æŸ¥æ‰¾å¯¹åº”çš„ç« èŠ‚ï¼ˆé€šè¿‡chapter_numberåŒ¹é…order_indexï¼‰
            chapter_result = await db.execute(
                select(Chapter).where(
                    Chapter.project_id == outline.project_id,
                    Chapter.chapter_number == outline.order_index
                )
            )
            chapter = chapter_result.scalar_one_or_none()
            
            if chapter:
                # åŒæ­¥æ›´æ–°ç« èŠ‚æ ‡é¢˜
                chapter.title = outline.title
                logger.info(f"ä¸€å¯¹ä¸€æ¨¡å¼ï¼šåŒæ­¥æ›´æ–°ç« èŠ‚ {chapter.id} çš„æ ‡é¢˜ä¸º '{outline.title}'")
            else:
                logger.debug(f"ä¸€å¯¹ä¸€æ¨¡å¼ï¼šæœªæ‰¾åˆ°å¯¹åº”çš„ç« èŠ‚ï¼ˆchapter_number={outline.order_index}ï¼‰")
        except Exception as e:
            logger.error(f"åŒæ­¥æ›´æ–°ç« èŠ‚æ ‡é¢˜å¤±è´¥: {str(e)}")
            # ä¸é˜»æ–­å¤§çº²æ›´æ–°æµç¨‹ï¼Œä»…è®°å½•é”™è¯¯
    
    await db.commit()
    await db.refresh(outline)
    return outline


@router.delete("/{outline_id}", summary="åˆ é™¤å¤§çº²")
async def delete_outline(
    outline_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """åˆ é™¤å¤§çº²ï¼ŒåŒæ—¶åˆ é™¤è¯¥å¤§çº²å¯¹åº”çš„æ‰€æœ‰ç« èŠ‚å’Œç›¸å…³çš„ä¼ç¬”æ•°æ®"""
    result = await db.execute(
        select(Outline).where(Outline.id == outline_id)
    )
    outline = result.scalar_one_or_none()
    
    if not outline:
        raise HTTPException(status_code=404, detail="å¤§çº²ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    project = await verify_project_access(outline.project_id, user_id, db)
    
    project_id = outline.project_id
    deleted_order = outline.order_index
    
    # è·å–è¦åˆ é™¤çš„ç« èŠ‚å¹¶è®¡ç®—æ€»å­—æ•°
    deleted_word_count = 0
    deleted_foreshadow_count = 0
    if project.outline_mode == 'one-to-one':
        # one-to-oneæ¨¡å¼ï¼šé€šè¿‡chapter_numberè·å–å¯¹åº”ç« èŠ‚
        chapters_result = await db.execute(
            select(Chapter).where(
                Chapter.project_id == project_id,
                Chapter.chapter_number == outline.order_index
            )
        )
        chapters_to_delete = chapters_result.scalars().all()
        deleted_word_count = sum(ch.word_count or 0 for ch in chapters_to_delete)
        
        # ğŸ”® æ¸…ç†ç« èŠ‚ç›¸å…³çš„ä¼ç¬”æ•°æ®å’Œå‘é‡è®°å¿†
        for chapter in chapters_to_delete:
            try:
                # æ¸…ç†å‘é‡æ•°æ®åº“ä¸­çš„è®°å¿†æ•°æ®
                await memory_service.delete_chapter_memories(
                    user_id=user_id,
                    project_id=project_id,
                    chapter_id=chapter.id
                )
                logger.info(f"âœ… å·²æ¸…ç†ç« èŠ‚ {chapter.id[:8]} çš„å‘é‡è®°å¿†æ•°æ®")
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸…ç†ç« èŠ‚ {chapter.id[:8]} å‘é‡è®°å¿†å¤±è´¥: {str(e)}")
            
            try:
                # æ¸…ç†ä¼ç¬”æ•°æ®ï¼ˆåˆ†ææ¥æºçš„ä¼ç¬”ï¼‰
                foreshadow_result = await foreshadow_service.delete_chapter_foreshadows(
                    db=db,
                    project_id=project_id,
                    chapter_id=chapter.id,
                    only_analysis_source=True
                )
                deleted_foreshadow_count += foreshadow_result.get('deleted_count', 0)
                if foreshadow_result.get('deleted_count', 0) > 0:
                    logger.info(f"ğŸ”® å·²æ¸…ç†ç« èŠ‚ {chapter.id[:8]} çš„ {foreshadow_result['deleted_count']} ä¸ªä¼ç¬”æ•°æ®")
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸…ç†ç« èŠ‚ {chapter.id[:8]} ä¼ç¬”æ•°æ®å¤±è´¥: {str(e)}")
        
        # åˆ é™¤ç« èŠ‚
        delete_result = await db.execute(
            delete(Chapter).where(
                Chapter.project_id == project_id,
                Chapter.chapter_number == outline.order_index
            )
        )
        deleted_chapters_count = delete_result.rowcount
        logger.info(f"ä¸€å¯¹ä¸€æ¨¡å¼ï¼šåˆ é™¤å¤§çº² {outline_id}ï¼ˆåºå·{outline.order_index}ï¼‰ï¼ŒåŒæ—¶åˆ é™¤äº†ç¬¬{outline.order_index}ç« ï¼ˆ{deleted_chapters_count}ä¸ªç« èŠ‚ï¼Œ{deleted_word_count}å­—ï¼Œ{deleted_foreshadow_count}ä¸ªä¼ç¬”ï¼‰")
    else:
        # one-to-manyæ¨¡å¼ï¼šé€šè¿‡outline_idè·å–å…³è”ç« èŠ‚
        chapters_result = await db.execute(
            select(Chapter).where(Chapter.outline_id == outline_id)
        )
        chapters_to_delete = chapters_result.scalars().all()
        deleted_word_count = sum(ch.word_count or 0 for ch in chapters_to_delete)
        
        # ğŸ”® æ¸…ç†ç« èŠ‚ç›¸å…³çš„ä¼ç¬”æ•°æ®å’Œå‘é‡è®°å¿†
        for chapter in chapters_to_delete:
            try:
                # æ¸…ç†å‘é‡æ•°æ®åº“ä¸­çš„è®°å¿†æ•°æ®
                await memory_service.delete_chapter_memories(
                    user_id=user_id,
                    project_id=project_id,
                    chapter_id=chapter.id
                )
                logger.info(f"âœ… å·²æ¸…ç†ç« èŠ‚ {chapter.id[:8]} çš„å‘é‡è®°å¿†æ•°æ®")
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸…ç†ç« èŠ‚ {chapter.id[:8]} å‘é‡è®°å¿†å¤±è´¥: {str(e)}")
            
            try:
                # æ¸…ç†ä¼ç¬”æ•°æ®ï¼ˆåˆ†ææ¥æºçš„ä¼ç¬”ï¼‰
                foreshadow_result = await foreshadow_service.delete_chapter_foreshadows(
                    db=db,
                    project_id=project_id,
                    chapter_id=chapter.id,
                    only_analysis_source=True
                )
                deleted_foreshadow_count += foreshadow_result.get('deleted_count', 0)
                if foreshadow_result.get('deleted_count', 0) > 0:
                    logger.info(f"ğŸ”® å·²æ¸…ç†ç« èŠ‚ {chapter.id[:8]} çš„ {foreshadow_result['deleted_count']} ä¸ªä¼ç¬”æ•°æ®")
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸…ç†ç« èŠ‚ {chapter.id[:8]} ä¼ç¬”æ•°æ®å¤±è´¥: {str(e)}")
        
        # åˆ é™¤ç« èŠ‚
        delete_result = await db.execute(
            delete(Chapter).where(Chapter.outline_id == outline_id)
        )
        deleted_chapters_count = delete_result.rowcount
        logger.info(f"ä¸€å¯¹å¤šæ¨¡å¼ï¼šåˆ é™¤å¤§çº² {outline_id}ï¼ŒåŒæ—¶åˆ é™¤äº† {deleted_chapters_count} ä¸ªå…³è”ç« èŠ‚ï¼ˆ{deleted_word_count}å­—ï¼Œ{deleted_foreshadow_count}ä¸ªä¼ç¬”ï¼‰")
    
    # æ›´æ–°é¡¹ç›®å­—æ•°
    if deleted_word_count > 0:
        project.current_words = max(0, project.current_words - deleted_word_count)
        logger.info(f"æ›´æ–°é¡¹ç›®å­—æ•°ï¼šå‡å°‘ {deleted_word_count} å­—")
    
    # åˆ é™¤å¤§çº²
    await db.delete(outline)
    
    # é‡æ–°æ’åºåç»­çš„å¤§çº²ï¼ˆåºå·-1ï¼‰
    result = await db.execute(
        select(Outline).where(
            Outline.project_id == project_id,
            Outline.order_index > deleted_order
        )
    )
    subsequent_outlines = result.scalars().all()
    
    for o in subsequent_outlines:
        o.order_index -= 1
    
    # å¦‚æœæ˜¯one-to-oneæ¨¡å¼ï¼Œè¿˜éœ€è¦é‡æ–°æ’åºåç»­ç« èŠ‚çš„chapter_number
    if project.outline_mode == 'one-to-one':
        chapters_result = await db.execute(
            select(Chapter).where(
                Chapter.project_id == project_id,
                Chapter.chapter_number > deleted_order
            ).order_by(Chapter.chapter_number)
        )
        subsequent_chapters = chapters_result.scalars().all()
        
        for ch in subsequent_chapters:
            ch.chapter_number -= 1
        
        logger.info(f"ä¸€å¯¹ä¸€æ¨¡å¼ï¼šé‡æ–°æ’åºäº† {len(subsequent_chapters)} ä¸ªåç»­ç« èŠ‚")
    
    await db.commit()
    
    return {
        "message": "å¤§çº²åˆ é™¤æˆåŠŸ",
        "deleted_chapters": deleted_chapters_count,
        "deleted_foreshadows": deleted_foreshadow_count
    }




async def _build_outline_continue_context(
    project: Project,
    latest_outlines: List[Outline],
    characters: List[Character],
    chapter_count: int,
    plot_stage: str,
    story_direction: str,
    requirements: str,
    db: AsyncSession
) -> dict:
    """
    æ„å»ºå¤§çº²ç»­å†™ä¸Šä¸‹æ–‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
    
    åŒ…å«å†…å®¹ï¼š
    1. é¡¹ç›®åŸºç¡€ä¿¡æ¯ï¼štitle, theme, genre, world_time_period, world_location,
       world_atmosphere, world_rules, narrative_perspective
    2. æœ€è¿‘10ç« çš„å®Œæ•´å¤§çº²structureï¼ˆè§£æJSONè½¬åŒ–ä¸ºæ–‡æœ¬ï¼‰
    3. æ‰€æœ‰è§’è‰²çš„å…¨éƒ¨ä¿¡æ¯
    4. ç”¨æˆ·è¾“å…¥ï¼šchapter_count, plot_stage, story_direction, requirements
    
    Args:
        project: é¡¹ç›®å¯¹è±¡
        latest_outlines: æ‰€æœ‰å·²æœ‰å¤§çº²åˆ—è¡¨
        characters: æ‰€æœ‰è§’è‰²åˆ—è¡¨
        chapter_count: è¦ç”Ÿæˆçš„ç« èŠ‚æ•°
        plot_stage: æƒ…èŠ‚é˜¶æ®µ
        story_direction: æ•…äº‹å‘å±•æ–¹å‘
        requirements: å…¶ä»–è¦æ±‚
        
    Returns:
        åŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å­—å…¸
    """
    context = {
        'project_info': '',
        'recent_outlines': '',
        'characters_info': '',
        'user_input': '',
        'stats': {
            'total_outlines': len(latest_outlines),
            'recent_outlines_count': 0,
            'characters_count': len(characters)
        }
    }
    
    try:
        # 1. é¡¹ç›®åŸºç¡€ä¿¡æ¯
        project_info_parts = [
            f"ã€é¡¹ç›®åŸºç¡€ä¿¡æ¯ã€‘",
            f"æ ‡é¢˜ï¼š{project.title}",
            f"ä¸»é¢˜ï¼š{project.theme or 'æœªè®¾å®š'}",
            f"ç±»å‹ï¼š{project.genre or 'æœªè®¾å®š'}",
            f"æ—¶ä»£èƒŒæ™¯ï¼š{project.world_time_period or 'æœªè®¾å®š'}",
            f"åœ°ç‚¹è®¾å®šï¼š{project.world_location or 'æœªè®¾å®š'}",
            f"æ°›å›´åŸºè°ƒï¼š{project.world_atmosphere or 'æœªè®¾å®š'}",
            f"ä¸–ç•Œè§„åˆ™ï¼š{project.world_rules or 'æœªè®¾å®š'}",
            f"å™äº‹è§†è§’ï¼š{project.narrative_perspective or 'ç¬¬ä¸‰äººç§°'}"
        ]
        context['project_info'] = "\n".join(project_info_parts)
        
        # 2. æœ€è¿‘10ç« çš„å®Œæ•´å¤§çº²structureï¼ˆè§£æJSONè½¬åŒ–ä¸ºæ–‡æœ¬ï¼‰
        recent_count = min(10, len(latest_outlines))
        if recent_count > 0:
            recent_outlines = latest_outlines[-recent_count:]
            context['stats']['recent_outlines_count'] = recent_count
            
            outline_texts = []
            outline_texts.append(f"ã€æœ€è¿‘{recent_count}ç« å¤§çº²è¯¦æƒ…ã€‘")
            
            for outline in recent_outlines:
                outline_text = f"\nç¬¬{outline.order_index}ç« ã€Š{outline.title}ã€‹"
                
                # å°è¯•è§£æstructureå­—æ®µ
                if outline.structure:
                    try:
                        structure_data = json.loads(outline.structure)
                        
                        # æå–å„ä¸ªå­—æ®µï¼ˆä½¿ç”¨å®é™…å­˜å‚¨çš„å­—æ®µåï¼‰
                        if structure_data.get('summary'):
                            outline_text += f"\n  æ¦‚è¦ï¼š{structure_data['summary']}"
                        
                        # key_points å¯¹åº” å…³é”®äº‹ä»¶
                        if structure_data.get('key_points'):
                            events = structure_data['key_points']
                            if isinstance(events, list):
                                outline_text += f"\n  å…³é”®äº‹ä»¶ï¼š{', '.join(events)}"
                            else:
                                outline_text += f"\n  å…³é”®äº‹ä»¶ï¼š{events}"
                        
                        # characters å¯¹åº” é‡ç‚¹è§’è‰²/ç»„ç»‡ï¼ˆå…¼å®¹æ–°æ—§æ ¼å¼ï¼‰
                        if structure_data.get('characters'):
                            chars = structure_data['characters']
                            if isinstance(chars, list):
                                # æ–°æ ¼å¼ï¼š[{"name": "xxx", "type": "character"/"organization"}]
                                # æ—§æ ¼å¼ï¼š["è§’è‰²å1", "è§’è‰²å2"]
                                char_names = []
                                org_names = []
                                for c in chars:
                                    if isinstance(c, dict):
                                        name = c.get('name', '')
                                        if c.get('type') == 'organization':
                                            org_names.append(name)
                                        else:
                                            char_names.append(name)
                                    elif isinstance(c, str):
                                        char_names.append(c)
                                if char_names:
                                    outline_text += f"\n  é‡ç‚¹è§’è‰²ï¼š{', '.join(char_names)}"
                                if org_names:
                                    outline_text += f"\n  æ¶‰åŠç»„ç»‡ï¼š{', '.join(org_names)}"
                            else:
                                outline_text += f"\n  é‡ç‚¹è§’è‰²ï¼š{chars}"
                        
                        # emotion å¯¹åº” æƒ…æ„ŸåŸºè°ƒ
                        if structure_data.get('emotion'):
                            outline_text += f"\n  æƒ…æ„ŸåŸºè°ƒï¼š{structure_data['emotion']}"
                        
                        # goal å¯¹åº” å™äº‹ç›®æ ‡
                        if structure_data.get('goal'):
                            outline_text += f"\n  å™äº‹ç›®æ ‡ï¼š{structure_data['goal']}"
                        
                        # scenes åœºæ™¯ä¿¡æ¯ï¼ˆå¯é€‰æ˜¾ç¤ºï¼‰
                        if structure_data.get('scenes'):
                            scenes = structure_data['scenes']
                            if isinstance(scenes, list) and scenes:
                                outline_text += f"\n  åœºæ™¯ï¼š{', '.join(scenes)}"
                            
                    except json.JSONDecodeError:
                        # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨contentå­—æ®µ
                        outline_text += f"\n  å†…å®¹ï¼š{outline.content}"
                else:
                    # æ²¡æœ‰structureï¼Œä½¿ç”¨content
                    outline_text += f"\n  å†…å®¹ï¼š{outline.content}"
                
                outline_texts.append(outline_text)
            
            context['recent_outlines'] = "\n".join(outline_texts)
            logger.info(f"  âœ… æœ€è¿‘å¤§çº²ï¼š{recent_count}ç« ")
        
        # 3. æ‰€æœ‰è§’è‰²çš„å…¨éƒ¨ä¿¡æ¯(åŒ…æ‹¬èŒä¸šä¿¡æ¯)
        if characters:
            from app.models.career import Career, CharacterCareer
            
            char_texts = []
            char_texts.append("ã€è§’è‰²ä¿¡æ¯ã€‘")
            
            for char in characters:
                char_text = f"\n{char.name}ï¼ˆ{'ç»„ç»‡' if char.is_organization else 'è§’è‰²'}ï¼Œ{char.role_type}ï¼‰"
                
                if char.personality:
                    char_text += f"\n  æ€§æ ¼ç‰¹ç‚¹ï¼š{char.personality}"
                
                if char.background:
                    char_text += f"\n  èƒŒæ™¯æ•…äº‹ï¼š{char.background}"
                
                if char.appearance:
                    char_text += f"\n  å¤–è²Œæè¿°ï¼š{char.appearance}"
                
                if char.traits:
                    char_text += f"\n  ç‰¹å¾æ ‡ç­¾ï¼š{char.traits}"
                
                # ä» character_relationships è¡¨æŸ¥è¯¢å…³ç³»
                from sqlalchemy import or_
                rels_result = await db.execute(
                    select(CharacterRelationship).where(
                        CharacterRelationship.project_id == project.id,
                        or_(
                            CharacterRelationship.character_from_id == char.id,
                            CharacterRelationship.character_to_id == char.id
                        )
                    )
                )
                rels = rels_result.scalars().all()
                if rels:
                    # æ”¶é›†ç›¸å…³è§’è‰²åç§°
                    related_ids = set()
                    for r in rels:
                        related_ids.add(r.character_from_id)
                        related_ids.add(r.character_to_id)
                    related_ids.discard(char.id)
                    if related_ids:
                        names_result = await db.execute(
                            select(Character.id, Character.name).where(Character.id.in_(related_ids))
                        )
                        name_map = {row.id: row.name for row in names_result}
                        rel_parts = []
                        for r in rels:
                            if r.character_from_id == char.id:
                                target_name = name_map.get(r.character_to_id, "æœªçŸ¥")
                            else:
                                target_name = name_map.get(r.character_from_id, "æœªçŸ¥")
                            rel_name = r.relationship_name or "ç›¸å…³"
                            rel_parts.append(f"ä¸{target_name}ï¼š{rel_name}")
                        char_text += f"\n  å…³ç³»ç½‘ç»œï¼š{'ï¼›'.join(rel_parts)}"
                
                # ç»„ç»‡ç‰¹æœ‰å­—æ®µ
                if char.is_organization:
                    if char.organization_type:
                        char_text += f"\n  ç»„ç»‡ç±»å‹ï¼š{char.organization_type}"
                    if char.organization_purpose:
                        char_text += f"\n  ç»„ç»‡å®—æ—¨ï¼š{char.organization_purpose}"
                    # ä» OrganizationMember è¡¨åŠ¨æ€æŸ¥è¯¢ç»„ç»‡æˆå‘˜
                    org_result = await db.execute(
                        select(Organization).where(Organization.character_id == char.id)
                    )
                    org = org_result.scalar_one_or_none()
                    if org:
                        members_result = await db.execute(
                            select(OrganizationMember, Character.name).join(
                                Character, OrganizationMember.character_id == Character.id
                            ).where(OrganizationMember.organization_id == org.id)
                        )
                        members = members_result.all()
                        if members:
                            member_parts = [f"{name}ï¼ˆ{m.position}ï¼‰" for m, name in members]
                            char_text += f"\n  ç»„ç»‡æˆå‘˜ï¼š{'ã€'.join(member_parts)}"
                
                # æŸ¥è¯¢è§’è‰²çš„èŒä¸šä¿¡æ¯
                if not char.is_organization:
                    try:
                        career_result = await db.execute(
                            select(Career, CharacterCareer)
                            .join(CharacterCareer, Career.id == CharacterCareer.career_id)
                            .where(CharacterCareer.character_id == char.id)
                        )
                        career_data = career_result.first()
                        
                        if career_data:
                            career, char_career = career_data
                            char_text += f"\n  èŒä¸šï¼š{career.name}"
                            if char_career.current_stage:
                                char_text += f"ï¼ˆ{char_career.current_stage}é˜¶æ®µï¼‰"
                            if char_career.career_type:
                                char_text += f"\n  èŒä¸šç±»å‹ï¼š{char_career.career_type}"
                    except Exception as e:
                        logger.warning(f"æŸ¥è¯¢è§’è‰² {char.name} çš„èŒä¸šä¿¡æ¯å¤±è´¥: {str(e)}")
                
                char_texts.append(char_text)
            
            context['characters_info'] = "\n".join(char_texts)
            logger.info(f"  âœ… è§’è‰²ä¿¡æ¯ï¼š{len(characters)}ä¸ªè§’è‰²")
        else:
            context['characters_info'] = "ã€è§’è‰²ä¿¡æ¯ã€‘\næš‚æ— è§’è‰²ä¿¡æ¯"
        
        # 4. ç”¨æˆ·è¾“å…¥
        user_input_parts = [
            "ã€ç”¨æˆ·è¾“å…¥ã€‘",
            f"è¦ç”Ÿæˆç« èŠ‚æ•°ï¼š{chapter_count}ç« ",
            f"æƒ…èŠ‚é˜¶æ®µï¼š{plot_stage}",
            f"æ•…äº‹å‘å±•æ–¹å‘ï¼š{story_direction}",
        ]
        if requirements:
            user_input_parts.append(f"å…¶ä»–è¦æ±‚ï¼š{requirements}")
        
        context['user_input'] = "\n".join(user_input_parts)
        
        # è®¡ç®—æ€»é•¿åº¦
        total_length = sum([
            len(context['project_info']),
            len(context['recent_outlines']),
            len(context['characters_info']),
            len(context['user_input'])
        ])
        context['stats']['total_length'] = total_length
        logger.info(f"ğŸ“Š å¤§çº²ç»­å†™ä¸Šä¸‹æ–‡æ€»é•¿åº¦: {total_length} å­—ç¬¦")
        
    except Exception as e:
        logger.error(f"âŒ æ„å»ºå¤§çº²ç»­å†™ä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}", exc_info=True)
    
    return context


async def _check_and_create_missing_characters_from_outlines(
    outline_data: list,
    project_id: str,
    db: AsyncSession,
    user_ai_service: AIService,
    user_id: str = None,
    enable_mcp: bool = True,
    tracker = None
) -> dict:
    """
    å¤§çº²ç”Ÿæˆ/ç»­å†™åï¼Œæ ¡éªŒstructureä¸­çš„charactersæ˜¯å¦å­˜åœ¨å¯¹åº”è§’è‰²ï¼Œ
    ä¸å­˜åœ¨çš„è‡ªåŠ¨æ ¹æ®å¤§çº²æ‘˜è¦ç”Ÿæˆè§’è‰²ä¿¡æ¯ã€‚
    
    Args:
        outline_data: å¤§çº²æ•°æ®åˆ—è¡¨ï¼ˆåŸå§‹JSONè§£æåçš„æ•°æ®ï¼ŒåŒ…å«charactersã€summaryç­‰å­—æ®µï¼‰
        project_id: é¡¹ç›®ID
        db: æ•°æ®åº“ä¼šè¯
        user_ai_service: AIæœåŠ¡å®ä¾‹
        user_id: ç”¨æˆ·ID
        enable_mcp: æ˜¯å¦å¯ç”¨MCP
        tracker: å¯é€‰ï¼ŒWizardProgressTrackerç”¨äºå‘é€è¿›åº¦
        
    Returns:
        {"created_count": int, "created_characters": list}
    """
    try:
        from app.services.auto_character_service import get_auto_character_service
        
        auto_char_service = get_auto_character_service(user_ai_service)
        
        # å®šä¹‰è¿›åº¦å›è°ƒ
        async def progress_cb(message: str):
            if tracker:
                # æ³¨æ„ï¼šè¿™é‡Œä¸èƒ½ç›´æ¥yieldï¼Œéœ€è¦é€šè¿‡å…¶ä»–æ–¹å¼å¤„ç†
                logger.info(f"  ğŸ“Œ {message}")
        
        result = await auto_char_service.check_and_create_missing_characters(
            project_id=project_id,
            outline_data_list=outline_data,
            db=db,
            user_id=user_id,
            enable_mcp=enable_mcp,
            progress_callback=progress_cb
        )
        
        if result["created_count"] > 0:
            logger.info(
                f"ğŸ­ ã€è§’è‰²æ ¡éªŒå®Œæˆã€‘è‡ªåŠ¨åˆ›å»ºäº† {result['created_count']} ä¸ªç¼ºå¤±è§’è‰²: "
                f"{', '.join(c.name for c in result['created_characters'])}"
            )
        
        return result
        
    except Exception as e:
        logger.error(f"âš ï¸ ã€è§’è‰²æ ¡éªŒã€‘æ ¡éªŒå¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}", exc_info=True)
        return {"created_count": 0, "created_characters": []}


async def _check_and_create_missing_organizations_from_outlines(
    outline_data: list,
    project_id: str,
    db: AsyncSession,
    user_ai_service: AIService,
    user_id: str = None,
    enable_mcp: bool = True,
    tracker = None
) -> dict:
    """
    å¤§çº²ç”Ÿæˆ/ç»­å†™åï¼Œæ ¡éªŒstructureä¸­çš„charactersï¼ˆtype=organizationï¼‰æ˜¯å¦å­˜åœ¨å¯¹åº”ç»„ç»‡ï¼Œ
    ä¸å­˜åœ¨çš„è‡ªåŠ¨æ ¹æ®å¤§çº²æ‘˜è¦ç”Ÿæˆç»„ç»‡ä¿¡æ¯ã€‚
    
    Args:
        outline_data: å¤§çº²æ•°æ®åˆ—è¡¨ï¼ˆåŸå§‹JSONè§£æåçš„æ•°æ®ï¼ŒåŒ…å«charactersã€summaryç­‰å­—æ®µï¼‰
        project_id: é¡¹ç›®ID
        db: æ•°æ®åº“ä¼šè¯
        user_ai_service: AIæœåŠ¡å®ä¾‹
        user_id: ç”¨æˆ·ID
        enable_mcp: æ˜¯å¦å¯ç”¨MCP
        tracker: å¯é€‰ï¼ŒWizardProgressTrackerç”¨äºå‘é€è¿›åº¦
        
    Returns:
        {"created_count": int, "created_organizations": list}
    """
    try:
        from app.services.auto_organization_service import get_auto_organization_service
        
        auto_org_service = get_auto_organization_service(user_ai_service)
        
        # å®šä¹‰è¿›åº¦å›è°ƒ
        async def progress_cb(message: str):
            if tracker:
                logger.info(f"  ğŸ“Œ {message}")
        
        result = await auto_org_service.check_and_create_missing_organizations(
            project_id=project_id,
            outline_data_list=outline_data,
            db=db,
            user_id=user_id,
            enable_mcp=enable_mcp,
            progress_callback=progress_cb
        )
        
        if result["created_count"] > 0:
            logger.info(
                f"ğŸ›ï¸ ã€ç»„ç»‡æ ¡éªŒå®Œæˆã€‘è‡ªåŠ¨åˆ›å»ºäº† {result['created_count']} ä¸ªç¼ºå¤±ç»„ç»‡: "
                f"{', '.join(c.name for c in result['created_organizations'])}"
            )
        
        return result
        
    except Exception as e:
        logger.error(f"âš ï¸ ã€ç»„ç»‡æ ¡éªŒã€‘æ ¡éªŒå¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}", exc_info=True)
        return {"created_count": 0, "created_organizations": []}


class JSONParseError(Exception):
    """JSONè§£æå¤±è´¥å¼‚å¸¸ï¼Œç”¨äºè§¦å‘é‡è¯•"""
    def __init__(self, message: str, original_content: str = ""):
        super().__init__(message)
        self.original_content = original_content


def _parse_ai_response(ai_response: str, raise_on_error: bool = False) -> list:
    """
    è§£æAIå“åº”ä¸ºç« èŠ‚æ•°æ®åˆ—è¡¨ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„JSONæ¸…æ´—æ–¹æ³•ï¼‰
    
    Args:
        ai_response: AIè¿”å›çš„åŸå§‹æ–‡æœ¬
        raise_on_error: å¦‚æœä¸ºTrueï¼Œè§£æå¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯è¿”å›fallbackæ•°æ®
        
    Returns:
        è§£æåçš„ç« èŠ‚æ•°æ®åˆ—è¡¨
        
    Raises:
        JSONParseError: å½“raise_on_error=Trueä¸”è§£æå¤±è´¥æ—¶æŠ›å‡º
    """
    try:
        # ä½¿ç”¨ç»Ÿä¸€çš„JSONæ¸…æ´—æ–¹æ³•ï¼ˆä»AIServiceå¯¼å…¥ï¼‰
        from app.services.ai_service import AIService
        ai_service_temp = AIService()
        cleaned_text = ai_service_temp._clean_json_response(ai_response)
        
        outline_data = json.loads(cleaned_text)
        
        # ç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
        if not isinstance(outline_data, list):
            # å¦‚æœæ˜¯å¯¹è±¡ï¼Œå°è¯•æå–chapterså­—æ®µ
            if isinstance(outline_data, dict):
                outline_data = outline_data.get("chapters", [outline_data])
            else:
                outline_data = [outline_data]
        
        # éªŒè¯è§£æç»“æœæ˜¯å¦æœ‰æ•ˆï¼ˆè‡³å°‘æœ‰ä¸€ä¸ªæœ‰æ•ˆç« èŠ‚ï¼‰
        valid_chapters = [
            ch for ch in outline_data
            if isinstance(ch, dict) and (ch.get("title") or ch.get("summary") or ch.get("content"))
        ]
        
        if not valid_chapters:
            error_msg = "è§£æç»“æœæ— æ•ˆï¼šæœªæ‰¾åˆ°æœ‰æ•ˆçš„ç« èŠ‚æ•°æ®"
            logger.error(f"âŒ {error_msg}")
            if raise_on_error:
                raise JSONParseError(error_msg, ai_response)
            return [{
                "title": "AIç”Ÿæˆçš„å¤§çº²",
                "content": ai_response[:1000],
                "summary": ai_response[:1000]
            }]
        
        logger.info(f"âœ… æˆåŠŸè§£æ {len(valid_chapters)} ä¸ªç« èŠ‚æ•°æ®")
        return valid_chapters
        
    except json.JSONDecodeError as e:
        error_msg = f"JSONè§£æå¤±è´¥: {e}"
        logger.error(f"âŒ AIå“åº”è§£æå¤±è´¥: {e}")
        
        if raise_on_error:
            raise JSONParseError(error_msg, ai_response)
        
        # è¿”å›ä¸€ä¸ªåŒ…å«åŸå§‹å†…å®¹çš„ç« èŠ‚
        return [{
            "title": "AIç”Ÿæˆçš„å¤§çº²",
            "content": ai_response[:1000],
            "summary": ai_response[:1000]
        }]
    except JSONParseError:
        # é‡æ–°æŠ›å‡ºJSONParseError
        raise
    except Exception as e:
        error_msg = f"è§£æå¼‚å¸¸: {str(e)}"
        logger.error(f"âŒ {error_msg}")
        
        if raise_on_error:
            raise JSONParseError(error_msg, ai_response)
        
        return [{
            "title": "è§£æå¼‚å¸¸çš„å¤§çº²",
            "content": "ç³»ç»Ÿé”™è¯¯",
            "summary": "ç³»ç»Ÿé”™è¯¯"
        }]


async def _save_outlines(
    project_id: str,
    outline_data: list,
    db: AsyncSession,
    start_index: int = 1
) -> List[Outline]:
    """
    ä¿å­˜å¤§çº²åˆ°æ•°æ®åº“ï¼ˆä¿®å¤ç‰ˆï¼šä»structureä¸­æå–titleå’Œcontentä¿å­˜åˆ°æ•°æ®åº“ï¼‰
    
    å¦‚æœé¡¹ç›®ä¸ºone-to-oneæ¨¡å¼ï¼ŒåŒæ—¶è‡ªåŠ¨åˆ›å»ºå¯¹åº”çš„ç« èŠ‚
    """
    # è·å–é¡¹ç›®ä¿¡æ¯ä»¥ç¡®å®šoutline_mode
    project_result = await db.execute(
        select(Project).where(Project.id == project_id)
    )
    project = project_result.scalar_one_or_none()
    
    outlines = []
    
    for idx, chapter_data in enumerate(outline_data):
        order_idx = chapter_data.get("chapter_number", start_index + idx)
        
        # ğŸ”§ ä¿®å¤ï¼šä»structureä¸­æå–titleå’Œsummary/contentä¿å­˜åˆ°æ•°æ®åº“
        chapter_title = chapter_data.get("title", f"ç¬¬{order_idx}ç« ")
        chapter_content = chapter_data.get("summary") or chapter_data.get("content", "")
        
        outline = Outline(
            project_id=project_id,
            title=chapter_title,  # ä»JSONä¸­æå–title
            content=chapter_content,  # ä»JSONä¸­æå–summaryæˆ–content
            structure=json.dumps(chapter_data, ensure_ascii=False),
            order_index=order_idx
        )
        db.add(outline)
        outlines.append(outline)
    
    # å¦‚æœæ˜¯one-to-oneæ¨¡å¼ï¼Œè‡ªåŠ¨åˆ›å»ºç« èŠ‚
    if project and project.outline_mode == 'one-to-one':
        await db.flush()  # ç¡®ä¿å¤§çº²æœ‰ID
        
        for outline in outlines:
            await db.refresh(outline)
            
            # ğŸ”§ ä»structureä¸­æå–titleå’Œsummaryç”¨äºåˆ›å»ºç« èŠ‚
            try:
                structure_data = json.loads(outline.structure) if outline.structure else {}
                chapter_title = structure_data.get("title", f"ç¬¬{outline.order_index}ç« ")
                chapter_summary = structure_data.get("summary") or structure_data.get("content", "")
            except json.JSONDecodeError:
                logger.warning(f"è§£æå¤§çº² {outline.id} çš„structureå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                chapter_title = f"ç¬¬{outline.order_index}ç« "
                chapter_summary = ""
            
            # ä¸ºæ¯ä¸ªå¤§çº²åˆ›å»ºå¯¹åº”çš„ç« èŠ‚
            chapter = Chapter(
                project_id=project_id,
                title=chapter_title,
                summary=chapter_summary,
                chapter_number=outline.order_index,
                sub_index=1,
                outline_id=None,  # one-to-oneæ¨¡å¼ä¸å…³è”outline_id
                status='pending',
                content=""
            )
            db.add(chapter)
        
        logger.info(f"ä¸€å¯¹ä¸€æ¨¡å¼ï¼šä¸º{len(outlines)}ä¸ªå¤§çº²è‡ªåŠ¨åˆ›å»ºäº†å¯¹åº”çš„ç« èŠ‚")
    
    return outlines


async def new_outline_generator(
    data: Dict[str, Any],
    db: AsyncSession,
    user_ai_service: AIService
) -> AsyncGenerator[str, None]:
    """å…¨æ–°ç”Ÿæˆå¤§çº²SSEç”Ÿæˆå™¨ï¼ˆMCPå¢å¼ºç‰ˆï¼‰"""
    db_committed = False
    # åˆå§‹åŒ–æ ‡å‡†è¿›åº¦è¿½è¸ªå™¨
    tracker = WizardProgressTracker("å¤§çº²")
    
    try:
        yield await tracker.start()
        
        project_id = data.get("project_id")
        # ç¡®ä¿chapter_countæ˜¯æ•´æ•°ï¼ˆå‰ç«¯å¯èƒ½ä¼ å­—ç¬¦ä¸²ï¼‰
        chapter_count = int(data.get("chapter_count", 10))
        enable_mcp = data.get("enable_mcp", True)
        
        # éªŒè¯é¡¹ç›®
        yield await tracker.loading("åŠ è½½é¡¹ç›®ä¿¡æ¯...", 0.3)
        result = await db.execute(
            select(Project).where(Project.id == project_id)
        )
        project = result.scalar_one_or_none()
        if not project:
            yield await tracker.error("é¡¹ç›®ä¸å­˜åœ¨", 404)
            return
        
        yield await tracker.loading(f"å‡†å¤‡ç”Ÿæˆ{chapter_count}ç« å¤§çº²...", 0.6)
        
        # è·å–è§’è‰²ä¿¡æ¯
        characters_result = await db.execute(
            select(Character).where(Character.project_id == project_id)
        )
        characters = characters_result.scalars().all()
        characters_info = _build_characters_info(characters)
        
        # è®¾ç½®ç”¨æˆ·ä¿¡æ¯ä»¥å¯ç”¨MCP
        user_id_for_mcp = data.get("user_id")
        if user_id_for_mcp:
            user_ai_service.user_id = user_id_for_mcp
            user_ai_service.db_session = db
        
        # ä½¿ç”¨æç¤ºè¯æ¨¡æ¿
        yield await tracker.preparing("å‡†å¤‡AIæç¤ºè¯...")
        template = await PromptService.get_template("OUTLINE_CREATE", user_id_for_mcp, db)
        prompt = PromptService.format_prompt(
            template,
            title=project.title,
            theme=data.get("theme") or project.theme or "æœªè®¾å®š",
            genre=data.get("genre") or project.genre or "é€šç”¨",
            chapter_count=chapter_count,
            narrative_perspective=data.get("narrative_perspective") or "ç¬¬ä¸‰äººç§°",
            time_period=project.world_time_period or "æœªè®¾å®š",
            location=project.world_location or "æœªè®¾å®š",
            atmosphere=project.world_atmosphere or "æœªè®¾å®š",
            rules=project.world_rules or "æœªè®¾å®š",
            characters_info=characters_info or "æš‚æ— è§’è‰²ä¿¡æ¯",
            requirements=data.get("requirements") or "",
            mcp_references=""
        )
        logger.debug(f"NEWæç¤ºè¯: {prompt}")
        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        model_param = data.get("model")
        provider_param = data.get("provider")
        logger.info(f"=== å¤§çº²ç”ŸæˆAIè°ƒç”¨å‚æ•° ===")
        logger.info(f"  providerå‚æ•°: {provider_param}")
        logger.info(f"  modelå‚æ•°: {model_param}")
        
        # âœ… æµå¼ç”Ÿæˆï¼ˆå¸¦å­—æ•°ç»Ÿè®¡å’Œè¿›åº¦ï¼‰
        estimated_total = chapter_count * 1000
        accumulated_text = ""
        chunk_count = 0
        
        yield await tracker.generating(current_chars=0, estimated_total=estimated_total)
        
        async for chunk in user_ai_service.generate_text_stream(
            prompt=prompt,
            provider=provider_param,
            model=model_param
        ):
            chunk_count += 1
            accumulated_text += chunk
            
            # å‘é€å†…å®¹å—
            yield await tracker.generating_chunk(chunk)
            
            # å®šæœŸæ›´æ–°è¿›åº¦
            if chunk_count % 10 == 0:
                yield await tracker.generating(
                    current_chars=len(accumulated_text),
                    estimated_total=estimated_total
                )
            
            # æ¯20ä¸ªå—å‘é€å¿ƒè·³
            if chunk_count % 20 == 0:
                yield await tracker.heartbeat()
        
        yield await tracker.parsing("è§£æå¤§çº²æ•°æ®...")
        
        ai_content = accumulated_text
        ai_response = {"content": ai_content}
        
        # è§£æå“åº”ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        max_retries = 2
        retry_count = 0
        outline_data = None
        
        while retry_count <= max_retries:
            try:
                # ä½¿ç”¨ raise_on_error=Trueï¼Œè§£æå¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
                outline_data = _parse_ai_response(ai_content, raise_on_error=True)
                break  # è§£ææˆåŠŸï¼Œè·³å‡ºå¾ªç¯
                
            except JSONParseError as e:
                retry_count += 1
                if retry_count > max_retries:
                    # è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨fallbackæ•°æ®
                    logger.error(f"âŒ å¤§çº²è§£æå¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries})ï¼Œä½¿ç”¨fallbackæ•°æ®")
                    yield await tracker.warning("è§£æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
                    outline_data = _parse_ai_response(ai_content, raise_on_error=False)
                    break
                
                logger.warning(f"âš ï¸ JSONè§£æå¤±è´¥ï¼ˆç¬¬{retry_count}æ¬¡ï¼‰ï¼Œæ­£åœ¨é‡è¯•...")
                yield await tracker.retry(retry_count, max_retries, "JSONè§£æå¤±è´¥")
                
                # é‡è¯•æ—¶é‡ç½®ç”Ÿæˆè¿›åº¦
                tracker.reset_generating_progress()
                
                # é‡æ–°è°ƒç”¨AIç”Ÿæˆ
                accumulated_text = ""
                chunk_count = 0
                
                # åœ¨promptä¸­æ·»åŠ æ ¼å¼å¼ºè°ƒ
                retry_prompt = prompt + "\n\nã€é‡è¦æé†’ã€‘è¯·ç¡®ä¿è¿”å›å®Œæ•´çš„JSONæ•°ç»„ï¼Œä¸è¦æˆªæ–­ã€‚æ¯ä¸ªç« èŠ‚å¯¹è±¡å¿…é¡»åŒ…å«å®Œæ•´çš„titleã€summaryç­‰å­—æ®µã€‚"
                
                async for chunk in user_ai_service.generate_text_stream(
                    prompt=retry_prompt,
                    provider=provider_param,
                    model=model_param
                ):
                    chunk_count += 1
                    accumulated_text += chunk
                    
                    # å‘é€å†…å®¹å—
                    yield await tracker.generating_chunk(chunk)
                    
                    # æ¯20ä¸ªå—å‘é€å¿ƒè·³
                    if chunk_count % 20 == 0:
                        yield await tracker.heartbeat()
                
                ai_content = accumulated_text
                ai_response = {"content": ai_content}
                logger.info(f"ğŸ”„ é‡è¯•ç”Ÿæˆå®Œæˆï¼Œç´¯è®¡{len(ai_content)}å­—ç¬¦")
        
        # å…¨æ–°ç”Ÿæˆæ¨¡å¼ï¼šåˆ é™¤æ—§å¤§çº²å’Œå…³è”çš„æ‰€æœ‰ç« èŠ‚ã€ä¼ç¬”ã€åˆ†ææ•°æ®
        yield await tracker.saving("æ¸…ç†æ—§æ•°æ®ï¼ˆå¤§çº²ã€ç« èŠ‚ã€ä¼ç¬”ã€åˆ†æï¼‰...", 0.2)
        logger.info(f"ğŸ§¹ å…¨æ–°ç”Ÿæˆï¼šå¼€å§‹æ¸…ç†é¡¹ç›® {project_id} çš„æ‰€æœ‰æ—§æ•°æ®ï¼ˆoutline_mode: {project.outline_mode}ï¼‰")
        
        from sqlalchemy import delete as sql_delete
        
        # 1. å…ˆè·å–æ‰€æœ‰æ—§ç« èŠ‚IDï¼ˆç”¨äºåç»­æ¸…ç†ï¼‰
        old_chapters_result = await db.execute(
            select(Chapter).where(Chapter.project_id == project_id)
        )
        old_chapters = old_chapters_result.scalars().all()
        old_chapter_ids = [ch.id for ch in old_chapters]
        deleted_word_count = sum(ch.word_count or 0 for ch in old_chapters)
        
        # 2. æ¸…ç†ä¼ç¬”æ•°æ®ï¼ˆåˆ é™¤åˆ†æä¼ç¬”ï¼Œé‡ç½®æ‰‹åŠ¨ä¼ç¬”ï¼‰
        try:
            foreshadow_result = await foreshadow_service.clear_project_foreshadows_for_reset(db, project_id)
            logger.info(f"âœ… ä¼ç¬”æ¸…ç†: åˆ é™¤ {foreshadow_result['deleted_count']} ä¸ªåˆ†æä¼ç¬”, é‡ç½® {foreshadow_result['reset_count']} ä¸ªæ‰‹åŠ¨ä¼ç¬”")
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†ä¼ç¬”æ•°æ®å¤±è´¥: {str(e)}")
            # ç»§ç»­æµç¨‹ï¼Œä½†è®°å½•é”™è¯¯
        
        # 3. æ¸…ç†ç« èŠ‚åˆ†ææ•°æ®ï¼ˆPlotAnalysisï¼‰
        try:
            # è™½ç„¶æœ‰CASCADEåˆ é™¤ï¼Œä½†æ˜¾å¼åˆ é™¤æ›´å¯æ§
            from app.models.memory import PlotAnalysis
            delete_analysis_result = await db.execute(
                sql_delete(PlotAnalysis).where(PlotAnalysis.project_id == project_id)
            )
            deleted_analysis_count = delete_analysis_result.rowcount
            logger.info(f"âœ… ç« èŠ‚åˆ†ææ¸…ç†: åˆ é™¤ {deleted_analysis_count} ä¸ªåˆ†æè®°å½•")
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†ç« èŠ‚åˆ†ææ•°æ®å¤±è´¥: {str(e)}")
        
        # 4. æ¸…ç†å‘é‡è®°å¿†æ•°æ®ï¼ˆStoryMemoryï¼‰
        try:
            from app.models.memory import StoryMemory
            delete_memory_result = await db.execute(
                sql_delete(StoryMemory).where(StoryMemory.project_id == project_id)
            )
            deleted_memory_count = delete_memory_result.rowcount
            if deleted_memory_count > 0:
                logger.info(f"âœ… å‘é‡è®°å¿†æ¸…ç†: åˆ é™¤ {deleted_memory_count} æ¡è®°å¿†æ•°æ®")
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†å‘é‡è®°å¿†æ•°æ®å¤±è´¥: {str(e)}")
        
        # 5. åˆ é™¤å‘é‡æ•°æ®åº“ä¸­çš„è®°å¿†ï¼ˆå¦‚æœæœ‰ç« èŠ‚ï¼‰
        if old_chapter_ids:
            try:
                user_id_for_memory = data.get("user_id")
                if user_id_for_memory:
                    for chapter_id in old_chapter_ids:
                        try:
                            await memory_service.delete_chapter_memories(
                                user_id=user_id_for_memory,
                                project_id=project_id,
                                chapter_id=chapter_id
                            )
                        except Exception as mem_err:
                            logger.debug(f"æ¸…ç†ç« èŠ‚ {chapter_id[:8]} å‘é‡è®°å¿†å¤±è´¥: {str(mem_err)}")
                    logger.info(f"âœ… å‘é‡æ•°æ®åº“æ¸…ç†: å·²æ¸…ç† {len(old_chapter_ids)} ä¸ªç« èŠ‚çš„å‘é‡è®°å¿†")
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸…ç†å‘é‡æ•°æ®åº“å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {str(e)}")
        
        # 6. åˆ é™¤æ‰€æœ‰æ—§ç« èŠ‚
        delete_chapters_result = await db.execute(
            sql_delete(Chapter).where(Chapter.project_id == project_id)
        )
        deleted_chapters_count = delete_chapters_result.rowcount
        logger.info(f"âœ… ç« èŠ‚æ¸…ç†: åˆ é™¤ {deleted_chapters_count} ä¸ªç« èŠ‚ï¼ˆ{deleted_word_count}å­—ï¼‰")
        
        # æ›´æ–°é¡¹ç›®å­—æ•°
        if deleted_word_count > 0:
            project.current_words = max(0, project.current_words - deleted_word_count)
            logger.info(f"æ›´æ–°é¡¹ç›®å­—æ•°ï¼šå‡å°‘ {deleted_word_count} å­—")
        
        # å†åˆ é™¤æ‰€æœ‰æ—§å¤§çº²
        delete_outlines_result = await db.execute(
            sql_delete(Outline).where(Outline.project_id == project_id)
        )
        deleted_outlines_count = delete_outlines_result.rowcount
        logger.info(f"âœ… å…¨æ–°ç”Ÿæˆï¼šåˆ é™¤äº† {deleted_outlines_count} ä¸ªæ—§å¤§çº²")
        
        # ä¿å­˜æ–°å¤§çº²
        yield await tracker.saving("ä¿å­˜å¤§çº²åˆ°æ•°æ®åº“...", 0.6)
        outlines = await _save_outlines(
            project_id, outline_data, db, start_index=1
        )
        
        # ğŸ­ è§’è‰²æ ¡éªŒï¼šæ£€æŸ¥å¤§çº²structureä¸­çš„charactersæ˜¯å¦å­˜åœ¨å¯¹åº”è§’è‰²
        yield await tracker.saving("ğŸ­ æ ¡éªŒè§’è‰²ä¿¡æ¯...", 0.7)
        try:
            char_check_result = await _check_and_create_missing_characters_from_outlines(
                outline_data=outline_data,
                project_id=project_id,
                db=db,
                user_ai_service=user_ai_service,
                user_id=data.get("user_id"),
                enable_mcp=data.get("enable_mcp", True),
                tracker=tracker
            )
            if char_check_result["created_count"] > 0:
                created_names = [c.name for c in char_check_result["created_characters"]]
                yield await tracker.saving(
                    f"ğŸ­ è‡ªåŠ¨åˆ›å»ºäº† {char_check_result['created_count']} ä¸ªè§’è‰²: {', '.join(created_names)}",
                    0.8
                )
        except Exception as e:
            logger.error(f"âš ï¸ è§’è‰²æ ¡éªŒå¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
        
        # ğŸ›ï¸ ç»„ç»‡æ ¡éªŒï¼šæ£€æŸ¥å¤§çº²structureä¸­çš„charactersï¼ˆtype=organizationï¼‰æ˜¯å¦å­˜åœ¨å¯¹åº”ç»„ç»‡
        yield await tracker.saving("ğŸ›ï¸ æ ¡éªŒç»„ç»‡ä¿¡æ¯...", 0.75)
        try:
            org_check_result = await _check_and_create_missing_organizations_from_outlines(
                outline_data=outline_data,
                project_id=project_id,
                db=db,
                user_ai_service=user_ai_service,
                user_id=data.get("user_id"),
                enable_mcp=data.get("enable_mcp", True),
                tracker=tracker
            )
            if org_check_result["created_count"] > 0:
                created_names = [c.name for c in org_check_result["created_organizations"]]
                yield await tracker.saving(
                    f"ğŸ›ï¸ è‡ªåŠ¨åˆ›å»ºäº† {org_check_result['created_count']} ä¸ªç»„ç»‡: {', '.join(created_names)}",
                    0.85
                )
        except Exception as e:
            logger.error(f"âš ï¸ ç»„ç»‡æ ¡éªŒå¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
        
        # è®°å½•å†å²
        history = GenerationHistory(
            project_id=project_id,
            prompt=prompt,
            generated_content=json.dumps(ai_response, ensure_ascii=False) if isinstance(ai_response, dict) else ai_response,
            model=data.get("model") or "default"
        )
        db.add(history)
        
        await db.commit()
        db_committed = True
        
        for outline in outlines:
            await db.refresh(outline)
        
        logger.info(f"å…¨æ–°ç”Ÿæˆå®Œæˆ - {len(outlines)} ç« ")
        
        yield await tracker.complete()
        
        # å‘é€æœ€ç»ˆç»“æœ
        yield await tracker.result({
            "message": f"æˆåŠŸç”Ÿæˆ{len(outlines)}ç« å¤§çº²",
            "total_chapters": len(outlines),
            "outlines": [
                {
                    "id": outline.id,
                    "project_id": outline.project_id,
                    "title": outline.title,
                    "content": outline.content,
                    "order_index": outline.order_index,
                    "structure": outline.structure,
                    "created_at": outline.created_at.isoformat() if outline.created_at else None,
                    "updated_at": outline.updated_at.isoformat() if outline.updated_at else None
                } for outline in outlines
            ]
        })
        
        yield await tracker.done()
        
    except GeneratorExit:
        logger.warning("å¤§çº²ç”Ÿæˆå™¨è¢«æå‰å…³é—­")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("å¤§çº²ç”Ÿæˆäº‹åŠ¡å·²å›æ»šï¼ˆGeneratorExitï¼‰")
    except Exception as e:
        logger.error(f"å¤§çº²ç”Ÿæˆå¤±è´¥: {str(e)}")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("å¤§çº²ç”Ÿæˆäº‹åŠ¡å·²å›æ»šï¼ˆå¼‚å¸¸ï¼‰")
        yield await tracker.error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")


async def continue_outline_generator(
    data: Dict[str, Any],
    db: AsyncSession,
    user_ai_service: AIService,
    user_id: str = "system"
) -> AsyncGenerator[str, None]:
    """å¤§çº²ç»­å†™SSEç”Ÿæˆå™¨ - åˆ†æ‰¹ç”Ÿæˆï¼Œæ¨é€è¿›åº¦ï¼ˆè®°å¿†+MCPå¢å¼ºç‰ˆï¼‰"""
    db_committed = False
    # åˆå§‹åŒ–æ ‡å‡†è¿›åº¦è¿½è¸ªå™¨
    tracker = WizardProgressTracker("å¤§çº²ç»­å†™")
    
    try:
        # === åˆå§‹åŒ–é˜¶æ®µ ===
        yield await tracker.start("å¼€å§‹ç»­å†™å¤§çº²...")
        
        project_id = data.get("project_id")
        # ç¡®ä¿chapter_countæ˜¯æ•´æ•°ï¼ˆå‰ç«¯å¯èƒ½ä¼ å­—ç¬¦ä¸²ï¼‰
        total_chapters_to_generate = int(data.get("chapter_count", 5))
        
        # éªŒè¯é¡¹ç›®
        yield await tracker.loading("åŠ è½½é¡¹ç›®ä¿¡æ¯...", 0.2)
        result = await db.execute(
            select(Project).where(Project.id == project_id)
        )
        project = result.scalar_one_or_none()
        if not project:
            yield await tracker.error("é¡¹ç›®ä¸å­˜åœ¨", 404)
            return
        
        # è·å–ç°æœ‰å¤§çº²
        yield await tracker.loading("åˆ†æå·²æœ‰å¤§çº²...", 0.5)
        existing_result = await db.execute(
            select(Outline)
            .where(Outline.project_id == project_id)
            .order_by(Outline.order_index)
        )
        existing_outlines = existing_result.scalars().all()
        
        if not existing_outlines:
            yield await tracker.error("ç»­å†™æ¨¡å¼éœ€è¦å·²æœ‰å¤§çº²ï¼Œå½“å‰é¡¹ç›®æ²¡æœ‰å¤§çº²", 400)
            return
        
        current_chapter_count = len(existing_outlines)
        last_chapter_number = existing_outlines[-1].order_index
        
        yield await tracker.loading(
            f"å½“å‰å·²æœ‰{str(current_chapter_count)}ç« ï¼Œå°†ç»­å†™{str(total_chapters_to_generate)}ç« ",
            0.8
        )
        
        # è·å–è§’è‰²ä¿¡æ¯
        characters_result = await db.execute(
            select(Character).where(Character.project_id == project_id)
        )
        characters = characters_result.scalars().all()
        characters_info = _build_characters_info(characters)

        # åˆ†æ‰¹é…ç½®
        batch_size = 5
        total_batches = (total_chapters_to_generate + batch_size - 1) // batch_size
        
        # æƒ…èŠ‚é˜¶æ®µæŒ‡å¯¼
        stage_instructions = {
            "development": "ç»§ç»­å±•å¼€æƒ…èŠ‚ï¼Œæ·±åŒ–è§’è‰²å…³ç³»ï¼Œæ¨è¿›ä¸»çº¿å†²çª",
            "climax": "è¿›å…¥æ•…äº‹é«˜æ½®ï¼ŒçŸ›ç›¾æ¿€åŒ–ï¼Œå…³é”®å†²çªçˆ†å‘",
            "ending": "è§£å†³ä¸»è¦å†²çªï¼Œæ”¶æŸä¼ç¬”ï¼Œç»™å‡ºç»“å±€"
        }
        stage_instruction = stage_instructions.get(data.get("plot_stage", "development"), "")
        
        # === æ‰¹æ¬¡ç”Ÿæˆé˜¶æ®µ ===
        all_new_outlines = []
        current_start_chapter = last_chapter_number + 1
        
        for batch_num in range(total_batches):
            # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„ç« èŠ‚æ•°
            remaining_chapters = int(total_chapters_to_generate) - len(all_new_outlines)
            current_batch_size = min(batch_size, remaining_chapters)
            
            # æ¯æ‰¹ä½¿ç”¨çš„è¿›åº¦é¢„ä¼°
            estimated_chars_per_batch = current_batch_size * 1000
            
            # é‡ç½®ç”Ÿæˆè¿›åº¦ä»¥ä¾¿äºæ¯æ‰¹ç‹¬ç«‹è®¡ç®—
            tracker.reset_generating_progress()
            
            yield await tracker.generating(
                current_chars=0,
                estimated_total=estimated_chars_per_batch,
                message=f"ğŸ“ ç¬¬{str(batch_num + 1)}/{str(total_batches)}æ‰¹: ç”Ÿæˆç¬¬{str(current_start_chapter)}-{str(current_start_chapter + current_batch_size - 1)}ç« "
            )
            
            # è·å–æœ€æ–°çš„å¤§çº²åˆ—è¡¨ï¼ˆåŒ…æ‹¬ä¹‹å‰æ‰¹æ¬¡ç”Ÿæˆçš„ï¼‰
            latest_result = await db.execute(
                select(Outline)
                .where(Outline.project_id == project_id)
                .order_by(Outline.order_index)
            )
            latest_outlines = latest_result.scalars().all()
            
            # ğŸš€ ä½¿ç”¨æ–°çš„ç®€åŒ–ä¸Šä¸‹æ–‡æ„å»º
            context = await _build_outline_continue_context(
                project=project,
                latest_outlines=latest_outlines,
                characters=characters,
                chapter_count=current_batch_size,
                plot_stage=data.get("plot_stage", "development"),
                story_direction=data.get("story_direction", "è‡ªç„¶å»¶ç»­"),
                requirements=data.get("requirements", ""),
                db=db
            )
            
            # æ—¥å¿—ç»Ÿè®¡
            stats = context['stats']
            logger.info(f"ğŸ“Š æ‰¹æ¬¡{batch_num + 1}å¤§çº²ä¸Šä¸‹æ–‡: æ€»å¤§çº²{stats['total_outlines']}, "
                       f"æœ€è¿‘{stats['recent_outlines_count']}ç« , "
                       f"è§’è‰²{stats['characters_count']}ä¸ª, "
                       f"é•¿åº¦{stats['total_length']}å­—ç¬¦")
            
            # è®¾ç½®ç”¨æˆ·ä¿¡æ¯ä»¥å¯ç”¨MCP
            if user_id:
                user_ai_service.user_id = user_id
                user_ai_service.db_session = db
            
            yield await tracker.generating(
                current_chars=0,
                estimated_total=estimated_chars_per_batch,
                message=f"ğŸ¤– è°ƒç”¨AIç”Ÿæˆç¬¬{str(batch_num + 1)}æ‰¹..."
            )
            
            # ä½¿ç”¨æ ‡å‡†ç»­å†™æç¤ºè¯æ¨¡æ¿ï¼ˆç®€åŒ–ç‰ˆï¼‰
            template = await PromptService.get_template("OUTLINE_CONTINUE", user_id, db)
            prompt = PromptService.format_prompt(
                template,
                # åŸºç¡€ä¿¡æ¯
                title=project.title,
                theme=project.theme or "æœªè®¾å®š",
                genre=project.genre or "é€šç”¨",
                narrative_perspective=project.narrative_perspective or "ç¬¬ä¸‰äººç§°",
                time_period=project.world_time_period or "æœªè®¾å®š",
                location=project.world_location or "æœªè®¾å®š",
                atmosphere=project.world_atmosphere or "æœªè®¾å®š",
                rules=project.world_rules or "æœªè®¾å®š",
                # ä¸Šä¸‹æ–‡ä¿¡æ¯
                recent_outlines=context['recent_outlines'],
                characters_info=context['characters_info'],
                # ç»­å†™å‚æ•°
                chapter_count=current_batch_size,
                start_chapter=current_start_chapter,
                end_chapter=current_start_chapter + current_batch_size - 1,
                current_chapter_count=len(latest_outlines),
                plot_stage_instruction=stage_instruction,
                story_direction=data.get("story_direction", "è‡ªç„¶å»¶ç»­"),
                requirements=data.get("requirements", ""),
                mcp_references=""
            )
            logger.debug(f" ç»­å†™æç¤ºè¯: {prompt}")
            # è°ƒç”¨AIç”Ÿæˆå½“å‰æ‰¹æ¬¡
            model_param = data.get("model")
            provider_param = data.get("provider")
            logger.info(f"=== ç»­å†™æ‰¹æ¬¡{batch_num + 1} AIè°ƒç”¨å‚æ•° ===")
            logger.info(f"  providerå‚æ•°: {provider_param}")
            logger.info(f"  modelå‚æ•°: {model_param}")
            
            # æµå¼ç”Ÿæˆå¹¶ç´¯ç§¯æ–‡æœ¬
            accumulated_text = ""
            chunk_count = 0
            
            async for chunk in user_ai_service.generate_text_stream(
                prompt=prompt,
                provider=provider_param,
                model=model_param
            ):
                chunk_count += 1
                accumulated_text += chunk
                
                # å‘é€å†…å®¹å—
                yield await tracker.generating_chunk(chunk)
                
                # å®šæœŸæ›´æ–°è¿›åº¦
                if chunk_count % 10 == 0:
                    yield await tracker.generating(
                        current_chars=len(accumulated_text),
                        estimated_total=estimated_chars_per_batch,
                        message=f"ğŸ“ ç¬¬{str(batch_num + 1)}/{str(total_batches)}æ‰¹ç”Ÿæˆä¸­"
                    )
                
                # æ¯20ä¸ªå—å‘é€å¿ƒè·³
                if chunk_count % 20 == 0:
                    yield await tracker.heartbeat()
            
            yield await tracker.parsing(f"âœ… ç¬¬{str(batch_num + 1)}æ‰¹AIç”Ÿæˆå®Œæˆï¼Œæ­£åœ¨è§£æ...")
            
            # æå–å†…å®¹
            ai_content = accumulated_text
            ai_response = {"content": ai_content}
            
            # è§£æå“åº”ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
            max_retries = 2
            retry_count = 0
            outline_data = None
            
            while retry_count <= max_retries:
                try:
                    # ä½¿ç”¨ raise_on_error=Trueï¼Œè§£æå¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
                    outline_data = _parse_ai_response(ai_content, raise_on_error=True)
                    break  # è§£ææˆåŠŸï¼Œè·³å‡ºå¾ªç¯
                    
                except JSONParseError as e:
                    retry_count += 1
                    if retry_count > max_retries:
                        # è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨fallbackæ•°æ®
                        logger.error(f"âŒ ç¬¬{batch_num + 1}æ‰¹è§£æå¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries})ï¼Œä½¿ç”¨fallbackæ•°æ®")
                        yield await tracker.warning(f"ç¬¬{str(batch_num + 1)}æ‰¹è§£æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
                        outline_data = _parse_ai_response(ai_content, raise_on_error=False)
                        break
                    
                    logger.warning(f"âš ï¸ ç¬¬{batch_num + 1}æ‰¹JSONè§£æå¤±è´¥ï¼ˆç¬¬{retry_count}æ¬¡ï¼‰ï¼Œæ­£åœ¨é‡è¯•...")
                    yield await tracker.retry(retry_count, max_retries, f"ç¬¬{str(batch_num + 1)}æ‰¹è§£æå¤±è´¥")
                    
                    # é‡è¯•æ—¶é‡ç½®ç”Ÿæˆè¿›åº¦
                    tracker.reset_generating_progress()
                    
                    # é‡æ–°è°ƒç”¨AIç”Ÿæˆ
                    accumulated_text = ""
                    chunk_count = 0
                    
                    # åœ¨promptä¸­æ·»åŠ æ ¼å¼å¼ºè°ƒ
                    retry_prompt = prompt + "\n\nã€é‡è¦æé†’ã€‘è¯·ç¡®ä¿è¿”å›å®Œæ•´çš„JSONæ•°ç»„ï¼Œä¸è¦æˆªæ–­ã€‚æ¯ä¸ªç« èŠ‚å¯¹è±¡å¿…é¡»åŒ…å«å®Œæ•´çš„titleã€summaryç­‰å­—æ®µã€‚"
                    
                    async for chunk in user_ai_service.generate_text_stream(
                        prompt=retry_prompt,
                        provider=provider_param,
                        model=model_param
                    ):
                        chunk_count += 1
                        accumulated_text += chunk
                        
                        # å‘é€å†…å®¹å—
                        yield await tracker.generating_chunk(chunk)
                        
                        # æ¯20ä¸ªå—å‘é€å¿ƒè·³
                        if chunk_count % 20 == 0:
                            yield await tracker.heartbeat()
                    
                    ai_content = accumulated_text
                    ai_response = {"content": ai_content}
                    logger.info(f"ğŸ”„ ç¬¬{batch_num + 1}æ‰¹é‡è¯•ç”Ÿæˆå®Œæˆï¼Œç´¯è®¡{len(ai_content)}å­—ç¬¦")
            
            # ä¿å­˜å½“å‰æ‰¹æ¬¡çš„å¤§çº²
            batch_outlines = await _save_outlines(
                project_id, outline_data, db, start_index=current_start_chapter
            )
            
            # ğŸ­ è§’è‰²æ ¡éªŒï¼šæ£€æŸ¥æœ¬æ‰¹å¤§çº²structureä¸­çš„charactersæ˜¯å¦å­˜åœ¨å¯¹åº”è§’è‰²
            try:
                char_check_result = await _check_and_create_missing_characters_from_outlines(
                    outline_data=outline_data,
                    project_id=project_id,
                    db=db,
                    user_ai_service=user_ai_service,
                    user_id=user_id,
                    enable_mcp=data.get("enable_mcp", True),
                    tracker=tracker
                )
                if char_check_result["created_count"] > 0:
                    created_names = [c.name for c in char_check_result["created_characters"]]
                    yield await tracker.saving(
                        f"ğŸ­ ç¬¬{str(batch_num + 1)}æ‰¹ï¼šè‡ªåŠ¨åˆ›å»ºäº† {char_check_result['created_count']} ä¸ªè§’è‰²: {', '.join(created_names)}",
                        (batch_num + 1) / total_batches * 0.5
                    )
                    # æ›´æ–°è§’è‰²åˆ—è¡¨ï¼ˆä¾›åç»­æ‰¹æ¬¡ä½¿ç”¨ï¼‰
                    characters.extend(char_check_result["created_characters"])
                    characters_info = _build_characters_info(characters)
            except Exception as e:
                logger.error(f"âš ï¸ ç¬¬{batch_num + 1}æ‰¹è§’è‰²æ ¡éªŒå¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
            
            # ğŸ›ï¸ ç»„ç»‡æ ¡éªŒï¼šæ£€æŸ¥æœ¬æ‰¹å¤§çº²structureä¸­çš„charactersï¼ˆtype=organizationï¼‰æ˜¯å¦å­˜åœ¨å¯¹åº”ç»„ç»‡
            try:
                org_check_result = await _check_and_create_missing_organizations_from_outlines(
                    outline_data=outline_data,
                    project_id=project_id,
                    db=db,
                    user_ai_service=user_ai_service,
                    user_id=user_id,
                    enable_mcp=data.get("enable_mcp", True),
                    tracker=tracker
                )
                if org_check_result["created_count"] > 0:
                    created_names = [c.name for c in org_check_result["created_organizations"]]
                    yield await tracker.saving(
                        f"ğŸ›ï¸ ç¬¬{str(batch_num + 1)}æ‰¹ï¼šè‡ªåŠ¨åˆ›å»ºäº† {org_check_result['created_count']} ä¸ªç»„ç»‡: {', '.join(created_names)}",
                        (batch_num + 1) / total_batches * 0.55
                    )
                    # æ›´æ–°è§’è‰²åˆ—è¡¨ï¼ˆç»„ç»‡ä¹Ÿæ˜¯Characterï¼Œä¾›åç»­æ‰¹æ¬¡ä½¿ç”¨ï¼‰
                    characters.extend(org_check_result["created_organizations"])
                    characters_info = _build_characters_info(characters)
            except Exception as e:
                logger.error(f"âš ï¸ ç¬¬{batch_num + 1}æ‰¹ç»„ç»‡æ ¡éªŒå¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
            
            # è®°å½•å†å²
            history = GenerationHistory(
                project_id=project_id,
                prompt=f"[ç»­å†™æ‰¹æ¬¡{batch_num + 1}/{total_batches}] {str(prompt)[:500]}",
                generated_content=json.dumps(ai_response, ensure_ascii=False) if isinstance(ai_response, dict) else ai_response,
                model=data.get("model") or "default"
            )
            db.add(history)
            
            # æäº¤å½“å‰æ‰¹æ¬¡
            await db.commit()
            
            for outline in batch_outlines:
                await db.refresh(outline)
            
            all_new_outlines.extend(batch_outlines)
            current_start_chapter += current_batch_size
            
            yield await tracker.saving(
                f"ğŸ’¾ ç¬¬{str(batch_num + 1)}æ‰¹ä¿å­˜æˆåŠŸï¼æœ¬æ‰¹ç”Ÿæˆ{str(len(batch_outlines))}ç« ï¼Œç´¯è®¡æ–°å¢{str(len(all_new_outlines))}ç« ",
                (batch_num + 1) / total_batches
            )
            
            logger.info(f"ç¬¬{str(batch_num + 1)}æ‰¹ç”Ÿæˆå®Œæˆï¼Œæœ¬æ‰¹ç”Ÿæˆ{str(len(batch_outlines))}ç« ")
        
        db_committed = True
        
        # è¿”å›æ‰€æœ‰å¤§çº²ï¼ˆåŒ…æ‹¬æ—§çš„å’Œæ–°çš„ï¼‰
        final_result = await db.execute(
            select(Outline)
            .where(Outline.project_id == project_id)
            .order_by(Outline.order_index)
        )
        all_outlines = final_result.scalars().all()
        
        yield await tracker.complete()
        
        # å‘é€æœ€ç»ˆç»“æœ
        yield await tracker.result({
            "message": f"ç»­å†™å®Œæˆï¼å…±{str(total_batches)}æ‰¹ï¼Œæ–°å¢{str(len(all_new_outlines))}ç« ï¼Œæ€»è®¡{str(len(all_outlines))}ç« ",
            "total_batches": total_batches,
            "new_chapters": len(all_new_outlines),
            "total_chapters": len(all_outlines),
            "outlines": [
                {
                    "id": outline.id,
                    "project_id": outline.project_id,
                    "title": outline.title,
                    "content": outline.content,
                    "order_index": outline.order_index,
                    "structure": outline.structure,
                    "created_at": outline.created_at.isoformat() if outline.created_at else None,
                    "updated_at": outline.updated_at.isoformat() if outline.updated_at else None
                } for outline in all_outlines
            ]
        })
        
        yield await tracker.done()
        
    except GeneratorExit:
        logger.warning("å¤§çº²ç»­å†™ç”Ÿæˆå™¨è¢«æå‰å…³é—­")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("å¤§çº²ç»­å†™äº‹åŠ¡å·²å›æ»šï¼ˆGeneratorExitï¼‰")
    except Exception as e:
        logger.error(f"å¤§çº²ç»­å†™å¤±è´¥: {str(e)}")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("å¤§çº²ç»­å†™äº‹åŠ¡å·²å›æ»šï¼ˆå¼‚å¸¸ï¼‰")
        yield await tracker.error(f"ç»­å†™å¤±è´¥: {str(e)}")


@router.post("/generate-stream", summary="AIç”Ÿæˆ/ç»­å†™å¤§çº²(SSEæµå¼)")
async def generate_outline_stream(
    data: Dict[str, Any],
    request: Request,
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    ä½¿ç”¨SSEæµå¼ç”Ÿæˆæˆ–ç»­å†™å°è¯´å¤§çº²ï¼Œå®æ—¶æ¨é€æ‰¹æ¬¡è¿›åº¦
    
    æ”¯æŒæ¨¡å¼ï¼š
    - auto: è‡ªåŠ¨åˆ¤æ–­ï¼ˆæ— å¤§çº²â†’æ–°å»ºï¼Œæœ‰å¤§çº²â†’ç»­å†™ï¼‰
    - new: å…¨æ–°ç”Ÿæˆ
    - continue: ç»­å†™æ¨¡å¼
    
    è¯·æ±‚ä½“ç¤ºä¾‹ï¼š
    {
        "project_id": "é¡¹ç›®ID",
        "chapter_count": 5,  // ç« èŠ‚æ•°
        "mode": "auto",  // auto/new/continue
        "theme": "æ•…äº‹ä¸»é¢˜",  // newæ¨¡å¼å¿…éœ€
        "story_direction": "æ•…äº‹å‘å±•æ–¹å‘",  // continueæ¨¡å¼å¯é€‰
        "plot_stage": "development",  // continueæ¨¡å¼ï¼šdevelopment/climax/ending
        "narrative_perspective": "ç¬¬ä¸‰äººç§°",
        "requirements": "å…¶ä»–è¦æ±‚",
        "provider": "openai",  // å¯é€‰
        "model": "gpt-4"  // å¯é€‰
    }
    """
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    project = await verify_project_access(data.get("project_id"), user_id, db)
    
    # åˆ¤æ–­æ¨¡å¼
    mode = data.get("mode", "auto")
    
    # è·å–ç°æœ‰å¤§çº²
    existing_result = await db.execute(
        select(Outline)
        .where(Outline.project_id == data.get("project_id"))
        .order_by(Outline.order_index)
    )
    existing_outlines = existing_result.scalars().all()
    
    # è‡ªåŠ¨åˆ¤æ–­æ¨¡å¼
    if mode == "auto":
        mode = "continue" if existing_outlines else "new"
        logger.info(f"è‡ªåŠ¨åˆ¤æ–­æ¨¡å¼ï¼š{'ç»­å†™' if existing_outlines else 'æ–°å»º'}")
    
    # è·å–ç”¨æˆ·ID
    user_id = getattr(request.state, "user_id", "system")
    
    # æ ¹æ®æ¨¡å¼é€‰æ‹©ç”Ÿæˆå™¨
    if mode == "new":
        return create_sse_response(new_outline_generator(data, db, user_ai_service))
    elif mode == "continue":
        if not existing_outlines:
            raise HTTPException(
                status_code=400,
                detail="ç»­å†™æ¨¡å¼éœ€è¦å·²æœ‰å¤§çº²ï¼Œå½“å‰é¡¹ç›®æ²¡æœ‰å¤§çº²"
            )
        return create_sse_response(continue_outline_generator(data, db, user_ai_service, user_id))
    else:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æŒçš„æ¨¡å¼: {mode}"
        )


async def expand_outline_generator(
    outline_id: str,
    data: Dict[str, Any],
    db: AsyncSession,
    user_ai_service: AIService
) -> AsyncGenerator[str, None]:
    """å•ä¸ªå¤§çº²å±•å¼€SSEç”Ÿæˆå™¨ - å®æ—¶æ¨é€è¿›åº¦ï¼ˆæ”¯æŒåˆ†æ‰¹ç”Ÿæˆï¼‰"""
    db_committed = False
    # åˆå§‹åŒ–æ ‡å‡†è¿›åº¦è¿½è¸ªå™¨
    tracker = WizardProgressTracker("å¤§çº²å±•å¼€")
    
    try:
        yield await tracker.start()
        
        target_chapter_count = int(data.get("target_chapter_count", 3))
        expansion_strategy = data.get("expansion_strategy", "balanced")
        enable_scene_analysis = data.get("enable_scene_analysis", True)
        auto_create_chapters = data.get("auto_create_chapters", False)
        batch_size = int(data.get("batch_size", 5))  # æ”¯æŒè‡ªå®šä¹‰æ‰¹æ¬¡å¤§å°
        
        # è·å–å¤§çº²
        yield await tracker.loading("åŠ è½½å¤§çº²ä¿¡æ¯...", 0.3)
        result = await db.execute(
            select(Outline).where(Outline.id == outline_id)
        )
        outline = result.scalar_one_or_none()
        
        if not outline:
            yield await tracker.error("å¤§çº²ä¸å­˜åœ¨", 404)
            return
        
        # è·å–é¡¹ç›®ä¿¡æ¯
        yield await tracker.loading("åŠ è½½é¡¹ç›®ä¿¡æ¯...", 0.7)
        project_result = await db.execute(
            select(Project).where(Project.id == outline.project_id)
        )
        project = project_result.scalar_one_or_none()
        if not project:
            yield await tracker.error("é¡¹ç›®ä¸å­˜åœ¨", 404)
            return
        
        yield await tracker.preparing(
            f"å‡†å¤‡å±•å¼€ã€Š{outline.title}ã€‹ä¸º {target_chapter_count} ç« ..."
        )
        
        # åˆ›å»ºå±•å¼€æœåŠ¡å®ä¾‹
        expansion_service = PlotExpansionService(user_ai_service)
        
        # åˆ†æå¤§çº²å¹¶ç”Ÿæˆç« èŠ‚è§„åˆ’ï¼ˆæ”¯æŒåˆ†æ‰¹ï¼‰
        if target_chapter_count > batch_size:
            yield await tracker.generating(
                current_chars=0,
                estimated_total=target_chapter_count * 500,
                message=f"ğŸ¤– AIåˆ†æ‰¹ç”Ÿæˆç« èŠ‚è§„åˆ’ï¼ˆæ¯æ‰¹{batch_size}ç« ï¼‰..."
            )
        else:
            yield await tracker.generating(
                current_chars=0,
                estimated_total=target_chapter_count * 500,
                message="ğŸ¤– AIåˆ†æå¤§çº²ï¼Œç”Ÿæˆç« èŠ‚è§„åˆ’..."
            )
        
        chapter_plans = await expansion_service.analyze_outline_for_chapters(
            outline=outline,
            project=project,
            db=db,
            target_chapter_count=target_chapter_count,
            expansion_strategy=expansion_strategy,
            enable_scene_analysis=enable_scene_analysis,
            provider=data.get("provider"),
            model=data.get("model"),
            batch_size=batch_size,
            progress_callback=None  # SSEä¸­æš‚ä¸æ”¯æŒåµŒå¥—å›è°ƒ
        )
        
        if not chapter_plans:
            yield await tracker.error("AIåˆ†æå¤±è´¥ï¼Œæœªèƒ½ç”Ÿæˆç« èŠ‚è§„åˆ’", 500)
            return
        
        yield await tracker.parsing(
            f"âœ… è§„åˆ’ç”Ÿæˆå®Œæˆï¼å…± {len(chapter_plans)} ä¸ªç« èŠ‚"
        )
        
        # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦åˆ›å»ºç« èŠ‚è®°å½•
        created_chapters = None
        if auto_create_chapters:
            yield await tracker.saving("ğŸ’¾ åˆ›å»ºç« èŠ‚è®°å½•...", 0.3)
            
            created_chapters = await expansion_service.create_chapters_from_plans(
                outline_id=outline_id,
                chapter_plans=chapter_plans,
                project_id=outline.project_id,
                db=db,
                start_chapter_number=None  # è‡ªåŠ¨è®¡ç®—ç« èŠ‚åºå·
            )
            
            await db.commit()
            db_committed = True
            
            # åˆ·æ–°ç« èŠ‚æ•°æ®
            for chapter in created_chapters:
                await db.refresh(chapter)
            
            yield await tracker.saving(
                f"âœ… æˆåŠŸåˆ›å»º {len(created_chapters)} ä¸ªç« èŠ‚è®°å½•",
                0.8
            )
        
        yield await tracker.complete()
        
        # æ„å»ºå“åº”æ•°æ®
        result_data = {
            "outline_id": outline_id,
            "outline_title": outline.title,
            "target_chapter_count": target_chapter_count,
            "actual_chapter_count": len(chapter_plans),
            "expansion_strategy": expansion_strategy,
            "chapter_plans": chapter_plans,
            "created_chapters": [
                {
                    "id": ch.id,
                    "chapter_number": ch.chapter_number,
                    "title": ch.title,
                    "summary": ch.summary,
                    "outline_id": ch.outline_id,
                    "sub_index": ch.sub_index,
                    "status": ch.status
                }
                for ch in created_chapters
            ] if created_chapters else None
        }
        
        yield await tracker.result(result_data)
        yield await tracker.done()
        
    except GeneratorExit:
        logger.warning("å¤§çº²å±•å¼€ç”Ÿæˆå™¨è¢«æå‰å…³é—­")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("å¤§çº²å±•å¼€äº‹åŠ¡å·²å›æ»šï¼ˆGeneratorExitï¼‰")
    except Exception as e:
        logger.error(f"å¤§çº²å±•å¼€å¤±è´¥: {str(e)}")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("å¤§çº²å±•å¼€äº‹åŠ¡å·²å›æ»šï¼ˆå¼‚å¸¸ï¼‰")
        yield await tracker.error(f"å±•å¼€å¤±è´¥: {str(e)}")


@router.post("/{outline_id}/create-single-chapter", summary="ä¸€å¯¹ä¸€åˆ›å»ºç« èŠ‚(ä¼ ç»Ÿæ¨¡å¼)")
async def create_single_chapter_from_outline(
    outline_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """
    ä¼ ç»Ÿæ¨¡å¼ï¼šä¸€ä¸ªå¤§çº²å¯¹åº”åˆ›å»ºä¸€ä¸ªç« èŠ‚
    
    é€‚ç”¨åœºæ™¯ï¼š
    - é¡¹ç›®çš„outline_modeä¸º'one-to-one'
    - ç›´æ¥å°†å¤§çº²å†…å®¹ä½œä¸ºç« èŠ‚æ‘˜è¦
    - ä¸è°ƒç”¨AIï¼Œä¸å±•å¼€
    
    æµç¨‹ï¼š
    1. éªŒè¯é¡¹ç›®æ¨¡å¼ä¸ºone-to-one
    2. æ£€æŸ¥è¯¥å¤§çº²æ˜¯å¦å·²åˆ›å»ºç« èŠ‚
    3. åˆ›å»ºç« èŠ‚è®°å½•ï¼ˆoutline_id=NULLï¼Œchapter_number=outline.order_indexï¼‰
    
    è¿”å›ï¼šåˆ›å»ºçš„ç« èŠ‚ä¿¡æ¯
    """
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    
    # è·å–å¤§çº²
    result = await db.execute(
        select(Outline).where(Outline.id == outline_id)
    )
    outline = result.scalar_one_or_none()
    
    if not outline:
        raise HTTPException(status_code=404, detail="å¤§çº²ä¸å­˜åœ¨")
    
    # éªŒè¯é¡¹ç›®æƒé™å¹¶è·å–é¡¹ç›®ä¿¡æ¯
    project = await verify_project_access(outline.project_id, user_id, db)
    
    # éªŒè¯é¡¹ç›®æ¨¡å¼
    if project.outline_mode != 'one-to-one':
        raise HTTPException(
            status_code=400,
            detail=f"å½“å‰é¡¹ç›®ä¸º{project.outline_mode}æ¨¡å¼ï¼Œä¸æ”¯æŒä¸€å¯¹ä¸€åˆ›å»ºã€‚è¯·ä½¿ç”¨å±•å¼€åŠŸèƒ½ã€‚"
        )
    
    # æ£€æŸ¥è¯¥å¤§çº²å¯¹åº”çš„ç« èŠ‚æ˜¯å¦å·²å­˜åœ¨
    existing_chapter_result = await db.execute(
        select(Chapter).where(
            Chapter.project_id == outline.project_id,
            Chapter.chapter_number == outline.order_index,
            Chapter.sub_index == 1
        )
    )
    existing_chapter = existing_chapter_result.scalar_one_or_none()
    
    if existing_chapter:
        raise HTTPException(
            status_code=400,
            detail=f"ç¬¬{outline.order_index}ç« å·²å­˜åœ¨ï¼Œä¸èƒ½é‡å¤åˆ›å»º"
        )
    
    try:
        # åˆ›å»ºç« èŠ‚ï¼ˆoutline_id=NULLè¡¨ç¤ºä¸€å¯¹ä¸€æ¨¡å¼ï¼‰
        new_chapter = Chapter(
            project_id=outline.project_id,
            title=outline.title,
            summary=outline.content,  # ä½¿ç”¨å¤§çº²å†…å®¹ä½œä¸ºæ‘˜è¦
            chapter_number=outline.order_index,
            sub_index=1,  # ä¸€å¯¹ä¸€æ¨¡å¼å›ºå®šä¸º1
            outline_id=None,  # ä¼ ç»Ÿæ¨¡å¼ä¸å…³è”outline_id
            status='pending'
        )
        
        db.add(new_chapter)
        await db.commit()
        await db.refresh(new_chapter)
        
        logger.info(f"ä¸€å¯¹ä¸€æ¨¡å¼ï¼šä¸ºå¤§çº² {outline.title} åˆ›å»ºç« èŠ‚ {new_chapter.chapter_number}")
        
        return {
            "message": "ç« èŠ‚åˆ›å»ºæˆåŠŸ",
            "chapter": {
                "id": new_chapter.id,
                "project_id": new_chapter.project_id,
                "title": new_chapter.title,
                "summary": new_chapter.summary,
                "chapter_number": new_chapter.chapter_number,
                "sub_index": new_chapter.sub_index,
                "outline_id": new_chapter.outline_id,
                "status": new_chapter.status,
                "created_at": new_chapter.created_at.isoformat() if new_chapter.created_at else None
            }
        }
        
    except Exception as e:
        logger.error(f"ä¸€å¯¹ä¸€åˆ›å»ºç« èŠ‚å¤±è´¥: {str(e)}", exc_info=True)
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºç« èŠ‚å¤±è´¥: {str(e)}")


@router.post("/{outline_id}/expand-stream", summary="å±•å¼€å•ä¸ªå¤§çº²ä¸ºå¤šç« (SSEæµå¼)")
async def expand_outline_to_chapters_stream(
    outline_id: str,
    data: Dict[str, Any],
    request: Request,
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    ä½¿ç”¨SSEæµå¼å±•å¼€å•ä¸ªå¤§çº²ï¼Œå®æ—¶æ¨é€è¿›åº¦
    
    è¯·æ±‚ä½“ç¤ºä¾‹ï¼š
    {
        "target_chapter_count": 3,  // ç›®æ ‡ç« èŠ‚æ•°
        "expansion_strategy": "balanced",  // balanced/climax/detail
        "auto_create_chapters": false,  // æ˜¯å¦è‡ªåŠ¨åˆ›å»ºç« èŠ‚
        "enable_scene_analysis": true,  // æ˜¯å¦å¯ç”¨åœºæ™¯åˆ†æ
        "provider": "openai",  // å¯é€‰
        "model": "gpt-4"  // å¯é€‰
    }
    
    è¿›åº¦é˜¶æ®µï¼š
    - 5% - å¼€å§‹å±•å¼€
    - 10% - åŠ è½½å¤§çº²ä¿¡æ¯
    - 15% - åŠ è½½é¡¹ç›®ä¿¡æ¯
    - 20% - å‡†å¤‡å±•å¼€å‚æ•°
    - 30% - AIåˆ†æå¤§çº²ï¼ˆè€—æ—¶ï¼‰
    - 70% - è§„åˆ’ç”Ÿæˆå®Œæˆ
    - 80% - åˆ›å»ºç« èŠ‚è®°å½•ï¼ˆå¦‚æœauto_create_chapters=Trueï¼‰
    - 90% - åˆ›å»ºå®Œæˆ
    - 95% - æ•´ç†ç»“æœæ•°æ®
    - 100% - å…¨éƒ¨å®Œæˆ
    """
    # è·å–å¤§çº²å¹¶éªŒè¯æƒé™
    result = await db.execute(
        select(Outline).where(Outline.id == outline_id)
    )
    outline = result.scalar_one_or_none()
    
    if not outline:
        raise HTTPException(status_code=404, detail="å¤§çº²ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(outline.project_id, user_id, db)
    
    return create_sse_response(expand_outline_generator(outline_id, data, db, user_ai_service))


@router.get("/{outline_id}/chapters", summary="è·å–å¤§çº²å…³è”çš„ç« èŠ‚")
async def get_outline_chapters(
    outline_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–æŒ‡å®šå¤§çº²å·²å±•å¼€çš„ç« èŠ‚åˆ—è¡¨
    
    ç”¨äºæ£€æŸ¥å¤§çº²æ˜¯å¦å·²ç»å±•å¼€è¿‡,å¦‚æœæœ‰åˆ™è¿”å›ç« èŠ‚ä¿¡æ¯
    """
    # è·å–å¤§çº²
    result = await db.execute(
        select(Outline).where(Outline.id == outline_id)
    )
    outline = result.scalar_one_or_none()
    
    if not outline:
        raise HTTPException(status_code=404, detail="å¤§çº²ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(outline.project_id, user_id, db)
    
    # æŸ¥è¯¢è¯¥å¤§çº²å…³è”çš„ç« èŠ‚
    chapters_result = await db.execute(
        select(Chapter)
        .where(Chapter.outline_id == outline_id)
        .order_by(Chapter.sub_index)
    )
    chapters = chapters_result.scalars().all()
    
    # å¦‚æœæœ‰ç« èŠ‚,è§£æå±•å¼€è§„åˆ’
    expansion_plans = []
    if chapters:
        for chapter in chapters:
            plan_data = None
            if chapter.expansion_plan:
                try:
                    plan_data = json.loads(chapter.expansion_plan)
                except json.JSONDecodeError:
                    logger.warning(f"ç« èŠ‚ {chapter.id} çš„expansion_planè§£æå¤±è´¥")
                    plan_data = None
            
            expansion_plans.append({
                "sub_index": chapter.sub_index,
                "title": chapter.title,
                "plot_summary": chapter.summary or "",
                "key_events": plan_data.get("key_events", []) if plan_data else [],
                "character_focus": plan_data.get("character_focus", []) if plan_data else [],
                "emotional_tone": plan_data.get("emotional_tone", "") if plan_data else "",
                "narrative_goal": plan_data.get("narrative_goal", "") if plan_data else "",
                "conflict_type": plan_data.get("conflict_type", "") if plan_data else "",
                "estimated_words": plan_data.get("estimated_words", 0) if plan_data else 0,
                "scenes": plan_data.get("scenes") if plan_data else None
            })
    
    return {
        "has_chapters": len(chapters) > 0,
        "outline_id": outline_id,
        "outline_title": outline.title,
        "chapter_count": len(chapters),
        "chapters": [
            {
                "id": ch.id,
                "chapter_number": ch.chapter_number,
                "title": ch.title,
                "summary": ch.summary,
                "sub_index": ch.sub_index,
                "status": ch.status,
                "word_count": ch.word_count
            }
            for ch in chapters
        ],
        "expansion_plans": expansion_plans if expansion_plans else None
    }


async def batch_expand_outlines_generator(
    data: Dict[str, Any],
    db: AsyncSession,
    user_ai_service: AIService
) -> AsyncGenerator[str, None]:
    """æ‰¹é‡å±•å¼€å¤§çº²SSEç”Ÿæˆå™¨ - å®æ—¶æ¨é€è¿›åº¦"""
    db_committed = False
    # åˆå§‹åŒ–æ ‡å‡†è¿›åº¦è¿½è¸ªå™¨
    tracker = WizardProgressTracker("æ‰¹é‡å¤§çº²å±•å¼€")
    
    try:
        yield await tracker.start()
        
        project_id = data.get("project_id")
        chapters_per_outline = int(data.get("chapters_per_outline", 3))
        expansion_strategy = data.get("expansion_strategy", "balanced")
        auto_create_chapters = data.get("auto_create_chapters", False)
        outline_ids = data.get("outline_ids")
        
        # è·å–é¡¹ç›®ä¿¡æ¯
        yield await tracker.loading("åŠ è½½é¡¹ç›®ä¿¡æ¯...", 0.5)
        project_result = await db.execute(
            select(Project).where(Project.id == project_id)
        )
        project = project_result.scalar_one_or_none()
        if not project:
            yield await tracker.error("é¡¹ç›®ä¸å­˜åœ¨", 404)
            return
        
        # è·å–è¦å±•å¼€çš„å¤§çº²åˆ—è¡¨
        yield await tracker.loading("è·å–å¤§çº²åˆ—è¡¨...", 0.8)
        if outline_ids:
            outlines_result = await db.execute(
                select(Outline)
                .where(
                    Outline.project_id == project_id,
                    Outline.id.in_(outline_ids)
                )
                .order_by(Outline.order_index)
            )
        else:
            outlines_result = await db.execute(
                select(Outline)
                .where(Outline.project_id == project_id)
                .order_by(Outline.order_index)
            )
        
        outlines = outlines_result.scalars().all()
        
        if not outlines:
            yield await tracker.error("æ²¡æœ‰æ‰¾åˆ°è¦å±•å¼€çš„å¤§çº²", 404)
            return
        
        total_outlines = len(outlines)
        yield await tracker.preparing(
            f"å…±æ‰¾åˆ° {total_outlines} ä¸ªå¤§çº²ï¼Œå¼€å§‹æ‰¹é‡å±•å¼€..."
        )
        
        # åˆ›å»ºå±•å¼€æœåŠ¡å®ä¾‹
        expansion_service = PlotExpansionService(user_ai_service)
        
        expansion_results = []
        total_chapters_created = 0
        skipped_outlines = []
        
        for idx, outline in enumerate(outlines):
            try:
                # è®¡ç®—å½“å‰å­è¿›åº¦ (0.0-1.0)ï¼Œç”¨äºgeneratingé˜¶æ®µ
                sub_progress = idx / max(total_outlines, 1)
                
                yield await tracker.generating(
                    current_chars=idx * chapters_per_outline * 500,
                    estimated_total=total_outlines * chapters_per_outline * 500,
                    message=f"ğŸ“ å¤„ç†ç¬¬ {idx + 1}/{total_outlines} ä¸ªå¤§çº²: {outline.title}"
                )
                
                # æ£€æŸ¥å¤§çº²æ˜¯å¦å·²ç»å±•å¼€è¿‡
                existing_chapters_result = await db.execute(
                    select(Chapter)
                    .where(Chapter.outline_id == outline.id)
                    .limit(1)
                )
                existing_chapter = existing_chapters_result.scalar_one_or_none()
                
                if existing_chapter:
                    logger.info(f"å¤§çº² {outline.title} (ID: {outline.id}) å·²ç»å±•å¼€è¿‡ï¼Œè·³è¿‡")
                    skipped_outlines.append({
                        "outline_id": outline.id,
                        "outline_title": outline.title,
                        "reason": "å·²å±•å¼€"
                    })
                    yield await tracker.generating(
                        current_chars=(idx + 1) * chapters_per_outline * 500,
                        estimated_total=total_outlines * chapters_per_outline * 500,
                        message=f"â­ï¸ {outline.title} å·²å±•å¼€è¿‡ï¼Œè·³è¿‡"
                    )
                    continue
                
                # åˆ†æå¤§çº²ç”Ÿæˆç« èŠ‚è§„åˆ’
                yield await tracker.generating(
                    current_chars=idx * chapters_per_outline * 500,
                    estimated_total=total_outlines * chapters_per_outline * 500,
                    message=f"ğŸ¤– AIåˆ†æå¤§çº²: {outline.title}"
                )
                
                chapter_plans = await expansion_service.analyze_outline_for_chapters(
                    outline=outline,
                    project=project,
                    db=db,
                    target_chapter_count=chapters_per_outline,
                    expansion_strategy=expansion_strategy,
                    enable_scene_analysis=data.get("enable_scene_analysis", True),
                    provider=data.get("provider"),
                    model=data.get("model")
                )
                
                yield await tracker.generating(
                    current_chars=(idx + 0.5) * chapters_per_outline * 500,
                    estimated_total=total_outlines * chapters_per_outline * 500,
                    message=f"âœ… {outline.title} è§„åˆ’ç”Ÿæˆå®Œæˆ ({len(chapter_plans)} ç« )"
                )
                
                created_chapters = None
                if auto_create_chapters:
                    # åˆ›å»ºç« èŠ‚è®°å½•
                    chapters = await expansion_service.create_chapters_from_plans(
                        outline_id=outline.id,
                        chapter_plans=chapter_plans,
                        project_id=outline.project_id,
                        db=db,
                        start_chapter_number=None  # è‡ªåŠ¨è®¡ç®—ç« èŠ‚åºå·
                    )
                    created_chapters = [
                        {
                            "id": ch.id,
                            "chapter_number": ch.chapter_number,
                            "title": ch.title,
                            "summary": ch.summary,
                            "outline_id": ch.outline_id,
                            "sub_index": ch.sub_index,
                            "status": ch.status
                        }
                        for ch in chapters
                    ]
                    total_chapters_created += len(chapters)
                    
                    yield await tracker.generating(
                        current_chars=(idx + 1) * chapters_per_outline * 500,
                        estimated_total=total_outlines * chapters_per_outline * 500,
                        message=f"ğŸ’¾ {outline.title} ç« èŠ‚åˆ›å»ºå®Œæˆ ({len(chapters)} ç« )"
                    )
                
                expansion_results.append({
                    "outline_id": outline.id,
                    "outline_title": outline.title,
                    "target_chapter_count": chapters_per_outline,
                    "actual_chapter_count": len(chapter_plans),
                    "expansion_strategy": expansion_strategy,
                    "chapter_plans": chapter_plans,
                    "created_chapters": created_chapters
                })
                
                logger.info(f"å¤§çº² {outline.title} å±•å¼€å®Œæˆï¼Œç”Ÿæˆ {len(chapter_plans)} ä¸ªç« èŠ‚è§„åˆ’")
                
            except Exception as e:
                logger.error(f"å±•å¼€å¤§çº² {outline.id} å¤±è´¥: {str(e)}", exc_info=True)
                yield await tracker.warning(
                    f"âŒ {outline.title} å±•å¼€å¤±è´¥: {str(e)}"
                )
                expansion_results.append({
                    "outline_id": outline.id,
                    "outline_title": outline.title,
                    "target_chapter_count": chapters_per_outline,
                    "actual_chapter_count": 0,
                    "expansion_strategy": expansion_strategy,
                    "chapter_plans": [],
                    "created_chapters": None,
                    "error": str(e)
                })
        
        yield await tracker.parsing("æ•´ç†ç»“æœæ•°æ®...")
        
        db_committed = True
        
        logger.info(f"æ‰¹é‡å±•å¼€å®Œæˆ: {len(expansion_results)} ä¸ªå¤§çº²ï¼Œè·³è¿‡ {len(skipped_outlines)} ä¸ªï¼Œå…±ç”Ÿæˆ {total_chapters_created} ä¸ªç« èŠ‚")
        
        yield await tracker.complete()
        
        # å‘é€æœ€ç»ˆç»“æœ
        result_data = {
            "project_id": project_id,
            "total_outlines_expanded": len(expansion_results),
            "total_chapters_created": total_chapters_created,
            "skipped_count": len(skipped_outlines),
            "skipped_outlines": skipped_outlines,
            "expansion_results": [
                {
                    "outline_id": result["outline_id"],
                    "outline_title": result["outline_title"],
                    "target_chapter_count": result["target_chapter_count"],
                    "actual_chapter_count": result["actual_chapter_count"],
                    "expansion_strategy": result["expansion_strategy"],
                    "chapter_plans": result["chapter_plans"],
                    "created_chapters": result.get("created_chapters")
                }
                for result in expansion_results
            ]
        }
        
        yield await tracker.result(result_data)
        yield await tracker.done()
        
    except GeneratorExit:
        logger.warning("æ‰¹é‡å±•å¼€ç”Ÿæˆå™¨è¢«æå‰å…³é—­")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("æ‰¹é‡å±•å¼€äº‹åŠ¡å·²å›æ»šï¼ˆGeneratorExitï¼‰")
    except Exception as e:
        logger.error(f"æ‰¹é‡å±•å¼€å¤±è´¥: {str(e)}")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("æ‰¹é‡å±•å¼€äº‹åŠ¡å·²å›æ»šï¼ˆå¼‚å¸¸ï¼‰")
        yield await SSEResponse.send_error(f"æ‰¹é‡å±•å¼€å¤±è´¥: {str(e)}")


@router.post("/batch-expand-stream", summary="æ‰¹é‡å±•å¼€å¤§çº²ä¸ºå¤šç« (SSEæµå¼)")
async def batch_expand_outlines_stream(
    data: Dict[str, Any],
    request: Request,
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    ä½¿ç”¨SSEæµå¼æ‰¹é‡å±•å¼€å¤§çº²ï¼Œå®æ—¶æ¨é€æ¯ä¸ªå¤§çº²çš„å¤„ç†è¿›åº¦
    
    è¯·æ±‚ä½“ç¤ºä¾‹ï¼š
    {
        "project_id": "é¡¹ç›®ID",
        "outline_ids": ["å¤§çº²ID1", "å¤§çº²ID2"],  // å¯é€‰ï¼Œä¸ä¼ åˆ™å±•å¼€æ‰€æœ‰å¤§çº²
        "chapters_per_outline": 3,  // æ¯ä¸ªå¤§çº²å±•å¼€å‡ ç« 
        "expansion_strategy": "balanced",  // balanced/climax/detail
        "auto_create_chapters": false,  // æ˜¯å¦è‡ªåŠ¨åˆ›å»ºç« èŠ‚
        "enable_scene_analysis": true,  // æ˜¯å¦å¯ç”¨åœºæ™¯åˆ†æ
        "provider": "openai",  // å¯é€‰
        "model": "gpt-4"  // å¯é€‰
    }
    """
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(data.get("project_id"), user_id, db)
    
    return create_sse_response(batch_expand_outlines_generator(data, db, user_ai_service))


@router.post("/{outline_id}/create-chapters-from-plans", response_model=CreateChaptersFromPlansResponse, summary="æ ¹æ®å·²æœ‰è§„åˆ’åˆ›å»ºç« èŠ‚")
async def create_chapters_from_existing_plans(
    outline_id: str,
    plans_request: CreateChaptersFromPlansRequest,
    request: Request,
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    æ ¹æ®å‰ç«¯ç¼“å­˜çš„ç« èŠ‚è§„åˆ’ç›´æ¥åˆ›å»ºç« èŠ‚è®°å½•ï¼Œé¿å…é‡å¤è°ƒç”¨AI
    
    ä½¿ç”¨åœºæ™¯ï¼š
    1. ç”¨æˆ·ç¬¬ä¸€æ¬¡è°ƒç”¨ /outlines/{outline_id}/expand?auto_create_chapters=false è·å–è§„åˆ’é¢„è§ˆ
    2. å‰ç«¯å±•ç¤ºè§„åˆ’ç»™ç”¨æˆ·ç¡®è®¤
    3. ç”¨æˆ·ç¡®è®¤åï¼Œå‰ç«¯è°ƒç”¨æ­¤æ¥å£ï¼Œä¼ é€’ç¼“å­˜çš„è§„åˆ’æ•°æ®ï¼Œç›´æ¥åˆ›å»ºç« èŠ‚
    
    ä¼˜åŠ¿ï¼š
    - é¿å…é‡å¤çš„AIè°ƒç”¨ï¼ŒèŠ‚çœTokenå’Œæ—¶é—´
    - ç¡®ä¿ç”¨æˆ·çœ‹åˆ°çš„é¢„è§ˆå’Œå®é™…åˆ›å»ºçš„ç« èŠ‚å®Œå…¨ä¸€è‡´
    - æå‡ç”¨æˆ·ä½“éªŒ
    
    å‚æ•°ï¼š
    - outline_id: è¦å±•å¼€çš„å¤§çº²ID
    - plans_request: åŒ…å«ä¹‹å‰AIç”Ÿæˆçš„ç« èŠ‚è§„åˆ’åˆ—è¡¨
    
    è¿”å›ï¼š
    - åˆ›å»ºçš„ç« èŠ‚åˆ—è¡¨å’Œç»Ÿè®¡ä¿¡æ¯
    """
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    
    # è·å–å¤§çº²
    result = await db.execute(
        select(Outline).where(Outline.id == outline_id)
    )
    outline = result.scalar_one_or_none()
    
    if not outline:
        raise HTTPException(status_code=404, detail="å¤§çº²ä¸å­˜åœ¨")
    
    # éªŒè¯é¡¹ç›®æƒé™
    await verify_project_access(outline.project_id, user_id, db)
    
    try:
        # éªŒè¯è§„åˆ’æ•°æ®
        if not plans_request.chapter_plans:
            raise HTTPException(status_code=400, detail="ç« èŠ‚è§„åˆ’åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        
        logger.info(f"æ ¹æ®å·²æœ‰è§„åˆ’ä¸ºå¤§çº² {outline_id} åˆ›å»º {len(plans_request.chapter_plans)} ä¸ªç« èŠ‚")
        
        # åˆ›å»ºå±•å¼€æœåŠ¡å®ä¾‹
        expansion_service = PlotExpansionService(user_ai_service)
        
        # å°†Pydanticæ¨¡å‹è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        chapter_plans_dict = [plan.model_dump() for plan in plans_request.chapter_plans]
        
        # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„è§„åˆ’åˆ›å»ºç« èŠ‚è®°å½•ï¼ˆä¸è°ƒç”¨AIï¼‰
        created_chapters = await expansion_service.create_chapters_from_plans(
            outline_id=outline_id,
            chapter_plans=chapter_plans_dict,
            project_id=outline.project_id,
            db=db,
            start_chapter_number=None  # è‡ªåŠ¨è®¡ç®—ç« èŠ‚åºå·
        )
        
        await db.commit()
        
        # åˆ·æ–°ç« èŠ‚æ•°æ®
        for chapter in created_chapters:
            await db.refresh(chapter)
        
        logger.info(f"æˆåŠŸæ ¹æ®å·²æœ‰è§„åˆ’åˆ›å»º {len(created_chapters)} ä¸ªç« èŠ‚è®°å½•")
        
        # æ„å»ºå“åº”
        return CreateChaptersFromPlansResponse(
            outline_id=outline_id,
            outline_title=outline.title,
            chapters_created=len(created_chapters),
            created_chapters=[
                {
                    "id": ch.id,
                    "chapter_number": ch.chapter_number,
                    "title": ch.title,
                    "summary": ch.summary,
                    "outline_id": ch.outline_id,
                    "sub_index": ch.sub_index,
                    "status": ch.status
                }
                for ch in created_chapters
            ]
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ ¹æ®å·²æœ‰è§„åˆ’åˆ›å»ºç« èŠ‚å¤±è´¥: {str(e)}", exc_info=True)
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºç« èŠ‚å¤±è´¥: {str(e)}")